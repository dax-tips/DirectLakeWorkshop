{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef57c0b5-52a1-4a68-816b-a2273b66e688",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Install Semantic Link Labs Python Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cae2d1-1076-45ce-8653-885e75cb12f4",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "#%pip uninstall -y -q \"builtin/semantic_link_labs-0.9.3-py3-none-any.whl\"\n",
    "#%pip install      -q \"builtin/semantic_link_labs-0.9.3-py3-none-any.whl\"\n",
    "%pip install -q --disable-pip-version-check semantic-link-labs\n",
    "#%pip install -q --disable-pip-version-check \"https://raw.githubusercontent.com/dax-tips/DirectLakeWorkshop/main/semantic_link_labs-0.9.3-py3-none-any.whl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782cf5f0-e43b-4875-a665-f5b69e8858f2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Get Lakehouse and Workspace Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe88dfa-77dc-4763-b330-40921e35ab32",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "import sempy_labs as labs\n",
    "import time\n",
    "\n",
    "LakehouseName = \"AdventureWorks\"\n",
    "SemanticModelName = f\"{LakehouseName}_model\"\n",
    "workspaceId = notebookutils.lakehouse.getWithProperties(LakehouseName)[\"workspaceId\"]\n",
    "lakehouseId = notebookutils.lakehouse.getWithProperties(LakehouseName)[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110caf3b-b01a-4003-9e0b-71c6e320cb59",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Define function to display Framing Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70acccb6-0f67-4fc7-aa0f-39cc09878972",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Optional\n",
    "import pyarrow.parquet as pq\n",
    "from sempy_labs._helper_functions import (\n",
    "    create_abfss_path,\n",
    "    save_as_delta_table,\n",
    "    _get_column_aggregate,\n",
    "    _create_dataframe,\n",
    "    _update_dataframe_datatypes,\n",
    "    resolve_workspace_name_and_id,\n",
    "    resolve_lakehouse_name_and_id,\n",
    "    _read_delta_table,\n",
    "    _delta_table_row_count,\n",
    "    _mount,\n",
    "    _create_spark_session,\n",
    ")\n",
    "from tqdm.auto import tqdm\n",
    "from uuid import UUID\n",
    "from datetime import datetime\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "def delta_analyzer_history(\n",
    "    table_name: str,\n",
    "    schema: Optional[str] = None,\n",
    "    lakehouse: Optional[str | UUID] = None,\n",
    "    workspace: Optional[str | UUID] = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analyzes the transaction log for a specified delta table and shows the results in dataframe.  One row per data modification operation.\n",
    "\n",
    "    Keeps track on the number of Parquet files, rowgroups, file size and #rows impacted by each change.\n",
    "\n",
    "    Incremental Framing effect: 100% = highly effective, 0% = no benefit at all\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    table_name : str\n",
    "        The delta table name.\n",
    "    schema : str, default=None\n",
    "        The schema name of the delta table.\n",
    "    lakehouse : str | uuid.UUID, default=None\n",
    "        The Fabric lakehouse name or ID.\n",
    "        Defaults to None which resolves to the lakehouse attached to the notebook.\n",
    "    workspace : str | uuid.UUID, default=None\n",
    "        The Fabric workspace name or ID used by the lakehouse.\n",
    "        Defaults to None which resolves to the workspace of the attached lakehouse\n",
    "        or if no lakehouse attached, resolves to the workspace of the notebook.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Displays a gantt visual showing a timeline for individual parquet files.\n",
    "    \"\"\"\n",
    "\n",
    "    import notebookutils\n",
    "\n",
    "    (workspace_name, workspace_id) = resolve_workspace_name_and_id(workspace=workspace)\n",
    "    (lakehouse_name, lakehouse_id) = resolve_lakehouse_name_and_id(\n",
    "        lakehouse=lakehouse, workspace=workspace\n",
    "    )\n",
    "\n",
    "    table_path = create_abfss_path(lakehouse_id, workspace_id, table_name, schema)\n",
    "    local_path = _mount(lakehouse=lakehouse, workspace=workspace)\n",
    "    table_path_local = f\"{local_path}/Tables/{table_name}\"\n",
    "    delta_table_path = f\"{table_path}/_delta_log\"\n",
    "\n",
    "    files = notebookutils.fs.ls(delta_table_path)\n",
    "    json_files = [file.name for file in files if file.name.endswith(\".json\")]\n",
    "\n",
    "    elementVersion = 0\n",
    "    totalSize: int = 0\n",
    "    totalRows: int = 0\n",
    "    totalFiles: int = 0\n",
    "    totalRowgroups: int = 0\n",
    "\n",
    "    changesArray = []\n",
    "    parquetFiles = []\n",
    "\n",
    "    myDateTimeFormat = \"%Y-%m-%d %H:%M:%S.%f\"\n",
    "\n",
    "    nowToEpoch = datetime.now().strftime(myDateTimeFormat)\n",
    "\n",
    "    num_latest_files = len(json_files)\n",
    "    for idx, file in enumerate(bar := tqdm(json_files), start=1):\n",
    "\n",
    "        bar.set_description(\n",
    "            f\"Analyzing the '{file}' parquet file ({idx}/{num_latest_files})...\"\n",
    "        )\n",
    "\n",
    "        changeTimestamp = datetime.strptime(\"2001-01-01 12:00:00.000\", myDateTimeFormat)\n",
    "        df = pd.read_json(\n",
    "            f\"{table_path}/_delta_log/{file}\", lines=True\n",
    "        )\n",
    "\n",
    "        rowsAdded: int = 0\n",
    "        sizeAdded: int = 0\n",
    "        rowsDeleted: int = 0\n",
    "        sizeDeleted: int = 0\n",
    "        filesAdded: int = 0\n",
    "        filesRemoved: int = 0\n",
    "\n",
    "        rowGroupsAdded: int = 0\n",
    "        rowGroupsRemoved: int = 0\n",
    "\n",
    "        totalFilesBeforeChange: int = totalFiles\n",
    "        totalRowGroupsBeforeChange: int = totalRowgroups\n",
    "        operation: str = \"\"\n",
    "        predicate: str = \"\"\n",
    "        tags: str = \"\"\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            if df.get(\"add\") is not None:\n",
    "                add_row = row[\"add\"]\n",
    "\n",
    "                if type(add_row) == dict:\n",
    "\n",
    "                    file_name = add_row[\"path\"]\n",
    "                    sizeAdded = sizeAdded + add_row[\"size\"]\n",
    "                    filesAdded = filesAdded + 1\n",
    "\n",
    "                    fileRowsAdded: int = 0\n",
    "\n",
    "                    fs_filename = f\"{table_path}/{file_name}\"\n",
    "\n",
    "                    if notebookutils.fs.exists(fs_filename):\n",
    "                        # parquet_file = pq.ParquetFile(f\"{table_path}/Tables/{table_name}/{file_name}\")\n",
    "                        parquet_file = pq.ParquetFile(\n",
    "                            table_path_local + f\"/{file_name}\"\n",
    "                        )\n",
    "                        for i in range(parquet_file.num_row_groups):\n",
    "                            row_group = parquet_file.metadata.row_group(i)\n",
    "                            num_rows = row_group.num_rows\n",
    "                            fileRowsAdded = fileRowsAdded + num_rows\n",
    "\n",
    "                            rowsAdded = rowsAdded + num_rows\n",
    "\n",
    "                        rowGroupsAdded = rowGroupsAdded + parquet_file.num_row_groups\n",
    "\n",
    "                        start = str(\n",
    "                            datetime.fromtimestamp(add_row[\"modificationTime\"] / 1000.0)\n",
    "                        )\n",
    "                        parquetFiles.append(\n",
    "                            {\n",
    "                                \"file\": file_name,\n",
    "                                \"start\": start,\n",
    "                                \"end\": nowToEpoch,\n",
    "                                \"rows\": fileRowsAdded,\n",
    "                                \"isCurrent\": 1,\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "            if df.get(\"remove\") is not None:\n",
    "                remove_row = row[\"remove\"]\n",
    "                if type(remove_row) == dict:\n",
    "                    file_name = remove_row[\"path\"]\n",
    "                    ### CHECK IF FILE EXISTS!!!\n",
    "                    fs_filename = f\"{table_path}/{file_name}\"\n",
    "\n",
    "                    if notebookutils.fs.exists(fs_filename):\n",
    "                        # parquet_file = pq.ParquetFile(f\"{table_path}/{file_name}\")\n",
    "                        parquet_file = pq.ParquetFile(\n",
    "                            table_path_local + f\"/{file_name}\"\n",
    "                        )\n",
    "                        for i in range(parquet_file.num_row_groups):\n",
    "                            row_group = parquet_file.metadata.row_group(i)\n",
    "                            num_rows = row_group.num_rows\n",
    "                            rowsDeleted = rowsDeleted + num_rows\n",
    "\n",
    "                        filesRemoved = filesRemoved + 1\n",
    "                        sizeDeleted = sizeDeleted + remove_row[\"size\"]\n",
    "\n",
    "                        rowGroupsRemoved = (\n",
    "                            rowGroupsRemoved + parquet_file.num_row_groups\n",
    "                        )\n",
    "\n",
    "                        result = next(\n",
    "                            (row for row in parquetFiles if row[\"file\"] == file_name),\n",
    "                            None,\n",
    "                        )\n",
    "                        if result is not None:\n",
    "                            result[\"isCurrent\"] = 0\n",
    "                            result[\"end\"] = str(\n",
    "                                datetime.fromtimestamp(\n",
    "                                    remove_row[\"deletionTimestamp\"] / 1000.0\n",
    "                                )\n",
    "                            )\n",
    "\n",
    "            if df.get(\"commitInfo\") is not None:\n",
    "                commit_row = row[\"commitInfo\"]\n",
    "                if type(commit_row) == dict:\n",
    "                    operation = commit_row[\"operation\"]\n",
    "\n",
    "                    if \"tags\" in commit_row:\n",
    "                        tags = commit_row[\"tags\"]\n",
    "\n",
    "                    if \"operationParameters\" in commit_row:\n",
    "                        operationParameters = commit_row[\"operationParameters\"]\n",
    "                        if \"predicate\" in operationParameters:\n",
    "                            predicate = operationParameters[\"predicate\"]\n",
    "\n",
    "                    if operation == \"VACUUM START\":\n",
    "                        totalFiles = totalFiles - int(\n",
    "                            commit_row[\"operationMetrics\"][\"numFilesToDelete\"]\n",
    "                        )\n",
    "                        totalSize = totalSize - int(\n",
    "                            commit_row[\"operationMetrics\"][\"sizeOfDataToDelete\"]\n",
    "                        )\n",
    "\n",
    "                    changeTimestamp = datetime.fromtimestamp(\n",
    "                        commit_row[\"timestamp\"] / 1000.0\n",
    "                    )\n",
    "\n",
    "        totalSize = totalSize + sizeAdded - sizeDeleted\n",
    "        totalRows = totalRows + rowsAdded - rowsDeleted\n",
    "        totalFiles = totalFiles + filesAdded - filesRemoved\n",
    "        totalRowgroups = totalRowgroups + rowGroupsAdded - rowGroupsRemoved\n",
    "\n",
    "        incrementalFramingEffect = 100\n",
    "        if sizeDeleted != 0:\n",
    "            incrementalFramingEffect = int((totalSize - sizeAdded * 1.0) / totalSize * 100000) / 1000\n",
    "            # incrementalFramingEffect = round(\n",
    "            #     (totalSize - sizeAdded * 1.0) / totalSize, 4\n",
    "            # )\n",
    "\n",
    "        changesArray.append(\n",
    "            [\n",
    "                elementVersion,\n",
    "                operation,\n",
    "                predicate,\n",
    "                changeTimestamp,\n",
    "                incrementalFramingEffect,\n",
    "                filesAdded,\n",
    "                filesRemoved,\n",
    "                totalFilesBeforeChange - filesRemoved,\n",
    "                totalFiles,\n",
    "                sizeAdded,\n",
    "                sizeDeleted,\n",
    "                totalSize,\n",
    "                rowGroupsAdded,\n",
    "                rowGroupsRemoved,\n",
    "                totalRowGroupsBeforeChange - rowGroupsRemoved,\n",
    "                totalRowgroups,\n",
    "                rowsAdded,\n",
    "                rowsDeleted,\n",
    "                rowsAdded - rowsDeleted,\n",
    "                totalRows,\n",
    "                tags,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        elementVersion = elementVersion + 1\n",
    "\n",
    "    #  /********************************************************************************************************************\n",
    "    #      Display Gantt Chart of files\n",
    "    #  ********************************************************************************************************************/\n",
    "    spec: str = (\n",
    "        \"\"\"{\n",
    "    \"$$schema\": 'https://vega.github.io/schema/vega-lite/v2.json',\n",
    "    \"description\": \"A simple bar chart with ranged data (aka Gantt Chart).\",\n",
    "    \"width\" : 1024 ,\n",
    "    \"data\": {\n",
    "        \"values\": %s\n",
    "    },\n",
    "    \"layer\":[\n",
    "        {\"mark\": \"bar\"},\n",
    "        {\"mark\": {\n",
    "        \"type\": \"text\",\n",
    "        \"align\": \"center\",\n",
    "        \"baseline\": \"middle\",\n",
    "        \"dx\": 40\n",
    "        },\n",
    "        \"encoding\": {\n",
    "        \"text\": {\"field\": \"rows\", \"type\": \"quantitative\", \"format\":\",\"},\n",
    "        \"color\":{\n",
    "        \"condition\": {\"test\": \"datum['isCurrent'] == 1\", \"value\": \"black\"},\n",
    "        \"value\": \"black\"\n",
    "            }\n",
    "        }\n",
    "        }],\n",
    "    \"encoding\": {\n",
    "        \"y\": {\"field\": \"file\", \"type\": \"ordinal\",\"sort\": \"isCurrent\",\"title\":null,\"axis\":{\"labelPadding\":15,\"labelLimit\":360}},\n",
    "        \"x\": {\"field\": \"start\", \"type\": \"temporal\",\"title\":null},\n",
    "        \"x2\": {\"field\": \"end\", \"type\": \"temporal\",\"title\":null},\n",
    "            \"color\": {\n",
    "            \"field\": \"isCurrent\",\n",
    "            \"scale\": {\"range\": [\"silver\", \"#ca8861\"]}\n",
    "            }\n",
    "    }\n",
    "    }\"\"\"\n",
    "        % (parquetFiles)\n",
    "    )\n",
    "\n",
    "    display(\n",
    "        HTML(\n",
    "            \"\"\"\n",
    "        <!DOCTYPE html>\n",
    "        <html>\n",
    "            <head>\n",
    "                <script src=\"https://cdn.jsdelivr.net/npm/vega@5\"></script>\n",
    "                <script src=\"https://cdn.jsdelivr.net/npm/vega-lite@5\"></script>\n",
    "                <script src=\"https://cdn.jsdelivr.net/npm/vega-embed@6\"></script>\n",
    "            </head>\n",
    "            <body>\n",
    "                <div id=\"vis\"></div>\n",
    "                <script type=\"text/javascript\">\n",
    "                    var spec = \"\"\"\n",
    "            + spec\n",
    "            + \"\"\";\n",
    "                    var opt = {\"renderer\": \"canvas\", \"actions\": false};\n",
    "                    vegaEmbed(\"#vis\", spec, opt);\n",
    "                </script>\n",
    "            </body>\n",
    "        </html>\"\"\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    changesDF = pd.DataFrame(\n",
    "        changesArray,\n",
    "        columns=[\n",
    "            \"Change Number\",\n",
    "            \"Change Type\",\n",
    "            \"Predicate\",\n",
    "            \"Modification Time\",\n",
    "            \"Incremental Effect\",\n",
    "            \"Files Added\",\n",
    "            \"Files Removed\",\n",
    "            \"Files Preserved\",\n",
    "            \"Files after change\",\n",
    "            \"Size Added\",\n",
    "            \"Sized Removed\",\n",
    "            \"Size after change\",\n",
    "            \"Rowgroups Added\",\n",
    "            \"Rowgroups Removed\",\n",
    "            \"Rowgroups Preserved\",\n",
    "            \"Rowgroups after change\",\n",
    "            \"Rows Added\",\n",
    "            \"Rows Removed\",\n",
    "            \"Rows Delta\",\n",
    "            \"Rows after change\",\n",
    "            \"Tags\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return changesDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1462661c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sempy_labs._helper_functions import (\n",
    "    resolve_report_id,\n",
    "    format_dax_object_name,\n",
    "    resolve_dataset_from_report,\n",
    "    _conv_b64,\n",
    "    _extract_json,\n",
    "    _add_part,\n",
    "    _decode_b64,\n",
    "    resolve_workspace_name_and_id,\n",
    "    _update_dataframe_datatypes,\n",
    "    _base_api,\n",
    "    _create_dataframe,\n",
    ")\n",
    "from typing import Optional, List\n",
    "import pandas as pd\n",
    "import json\n",
    "import base64\n",
    "from uuid import UUID\n",
    "from sempy._utils._log import log\n",
    "import sempy_labs._icons as icons\n",
    "import sempy_labs.report._report_helper as helper\n",
    "from sempy_labs._model_dependencies import get_measure_dependencies\n",
    "from jsonpath_ng.ext import parse\n",
    "import warnings\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a5e85a",
   "metadata": {},
   "source": [
    "## Create Simple Power BI Report to show data modification changes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4673d8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_name=\"Simple Report\"\n",
    "\n",
    "pbi_report:dict = {}\n",
    "pbi_report['config'] = \"\"\"{\n",
    "        \"version\": \"5.37\",\n",
    "        \"themeCollection\": {},\n",
    "        \"activeSectionIndex\": 0,\n",
    "        \"linguisticSchemaSyncVersion\": 0,\n",
    "        \"objects\": {\n",
    "            \"outspacePane\": [\n",
    "                {\n",
    "                    \"properties\": {\n",
    "                        \"expanded\": {\n",
    "                            \"expr\": {\n",
    "                                \"Literal\": {\n",
    "                                    \"Value\": \"false\"\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\"\"\"\n",
    "pbi_report['layoutOptimization']=0\n",
    "pbi_report['resourcePackages'] = [{'resourcePackage': {'disabled': False, 'items': [{'name': 'CY24SU10', 'path': 'BaseThemes/CY24SU10.json', 'type': 202}], 'name': 'SharedResources', 'type': 2}}]\n",
    "pbi_report['sections'] = [\n",
    "    {'config': '{}', \n",
    "    'displayName': 'Page 1', \n",
    "    'displayOption': 1, \n",
    "    'filters': '[]', \n",
    "    'height': 300.0, \n",
    "    'width': 600.0,\n",
    "    'name': 'a4c1ed461808909ae820', \n",
    "    'visualContainers':\n",
    "        [\n",
    "            {'config': '''{\n",
    "                        \"name\": \"Matrix\",\n",
    "                        \"layouts\": [\n",
    "                            {\n",
    "                                \"id\": 0,\n",
    "                                \"position\": {\n",
    "                                    \"x\": 310,\n",
    "                                    \"y\": 30,\n",
    "                                    \"z\": 1000,\n",
    "                                    \"width\": 253,\n",
    "                                    \"height\": 202\n",
    "                                }\n",
    "                            }\n",
    "                        ],\n",
    "                        \"singleVisual\": {\n",
    "                            \"visualType\": \"tableEx\",\n",
    "                            \"projections\": {\n",
    "                                \"Values\": [\n",
    "                                    {\n",
    "                                        \"queryRef\": \"DimDate.Month\"\n",
    "                                    },\n",
    "                                    {\n",
    "                                        \"queryRef\": \"Sum(FactInternetSales.SalesAmount)\"\n",
    "                                    }\n",
    "                                ]\n",
    "                            },\n",
    "                            \"prototypeQuery\": {\n",
    "                                \"Version\": 2,\n",
    "                                \"From\": [\n",
    "                                    {\n",
    "                                        \"Name\": \"d\",\n",
    "                                        \"Entity\": \"DimDate\",\n",
    "                                        \"Type\": 0\n",
    "                                    },\n",
    "                                    {\n",
    "                                        \"Name\": \"f\",\n",
    "                                        \"Entity\": \"FactInternetSales\",\n",
    "                                        \"Type\": 0\n",
    "                                    }\n",
    "                                ],\n",
    "                                \"Select\": [\n",
    "                                    {\n",
    "                                        \"Column\": {\n",
    "                                            \"Expression\": {\n",
    "                                                \"SourceRef\": {\n",
    "                                                    \"Source\": \"d\"\n",
    "                                                }\n",
    "                                            },\n",
    "                                            \"Property\": \"Month\"\n",
    "                                        },\n",
    "                                        \"Name\": \"DimDate.Month\",\n",
    "                                        \"NativeReferenceName\": \"Month\"\n",
    "                                    },\n",
    "                                    {\n",
    "                                        \"Aggregation\": {\n",
    "                                            \"Expression\": {\n",
    "                                                \"Column\": {\n",
    "                                                    \"Expression\": {\n",
    "                                                        \"SourceRef\": {\n",
    "                                                            \"Source\": \"f\"\n",
    "                                                        }\n",
    "                                                    },\n",
    "                                                    \"Property\": \"SalesAmount\"\n",
    "                                                }\n",
    "                                            },\n",
    "                                            \"Function\": 0\n",
    "                                        },\n",
    "                                        \"Name\": \"Sum(FactInternetSales.SalesAmount)\",\n",
    "                                        \"NativeReferenceName\": \"Sum of SalesAmount\"\n",
    "                                    }\n",
    "                                ]\n",
    "                            },\n",
    "                            \"drillFilterOtherVisuals\": true,\n",
    "                            \"vcObjects\": {\n",
    "                                \"dropShadow\": [\n",
    "                                    {\n",
    "                                        \"properties\": {\n",
    "                                            \"show\": {\n",
    "                                                \"expr\": {\n",
    "                                                    \"Literal\": {\n",
    "                                                        \"Value\": \"true\"\n",
    "                                                    }\n",
    "                                                }\n",
    "                                            }\n",
    "                                        }\n",
    "                                    }\n",
    "                                ]\n",
    "                            }\n",
    "                        }\n",
    "                    }''', 'filters': '[]', 'height': 202.46, 'width': 215.11, 'x': 319.67, 'y': 30.63, 'z': 1.0\n",
    "                },\n",
    "            {'config': \n",
    "                    '''{\n",
    "                        \"name\":\"Card\",\n",
    "                        \"layouts\":[\n",
    "                            {\n",
    "                            \"id\":0,\n",
    "                            \"position\":{\"x\":10,\"y\":30,\"z\":0,\"width\":238,\"height\":201}}\n",
    "                            ],\n",
    "                        \"singleVisual\":{\"visualType\":\"card\",\"projections\":{\"Values\":[{\"queryRef\":\"FactInternetSales.Count of Sales\"}]},\n",
    "\n",
    "\n",
    "                            \"prototypeQuery\": {\n",
    "                                \"Version\": 2,\n",
    "                                \"From\": [\n",
    "                                    {\n",
    "                                        \"Name\": \"f\",\n",
    "                                        \"Entity\": \"FactInternetSales\",\n",
    "                                        \"Type\": 0\n",
    "                                    }\n",
    "                                ],\n",
    "                                \"Select\": [\n",
    "                                    {\n",
    "                                        \"Measure\": {\n",
    "                                            \"Expression\": {\n",
    "                                                \"SourceRef\": {\n",
    "                                                    \"Source\": \"f\"\n",
    "                                                }\n",
    "                                            },\n",
    "                                            \"Property\": \"Count of Sales\"\n",
    "                                        },\n",
    "                                        \"Name\": \"FactInternetSales.Count of Sales\",\n",
    "                                        \"NativeReferenceName\": \"Count of Sales\"\n",
    "                                    }\n",
    "                                ],\n",
    "                                \"OrderBy\": [\n",
    "                                    {\n",
    "                                        \"Direction\": 2,\n",
    "                                        \"Expression\": {\n",
    "                                            \"Measure\": {\n",
    "                                                \"Expression\": {\n",
    "                                                    \"SourceRef\": {\n",
    "                                                        \"Source\": \"f\"\n",
    "                                                    }\n",
    "                                                },\n",
    "                                                \"Property\": \"Count of Sales\"\n",
    "                                            }\n",
    "                                        }\n",
    "                                    }\n",
    "                                ]\n",
    "                            },\n",
    "\n",
    "\n",
    "\n",
    "                            \"drillFilterOtherVisuals\":true,\n",
    "                            \"hasDefaultSort\":true,                           \n",
    "                            \"objects\": {\n",
    "                                \"labels\": [\n",
    "                                    {\n",
    "                                        \"properties\": {\n",
    "                                            \"fontSize\": {\n",
    "                                                \"expr\": {\n",
    "                                                    \"Literal\": {\n",
    "                                                        \"Value\": \"20D\"\n",
    "                                                    }\n",
    "                                                }\n",
    "                                            },\n",
    "                                            \"labelDisplayUnits\": {\n",
    "                                                \"expr\": {\n",
    "                                                    \"Literal\": {\n",
    "                                                        \"Value\": \"1D\"\n",
    "                                                    }\n",
    "                                                }\n",
    "                                            }\n",
    "                                        }\n",
    "                                    }\n",
    "                                ]\n",
    "                            },\n",
    "                            \"vcObjects\": {\n",
    "                                \"dropShadow\": [\n",
    "                                    {\n",
    "                                        \"properties\": {\n",
    "                                            \"show\": {\n",
    "                                                \"expr\": {\n",
    "                                                    \"Literal\": {\n",
    "                                                        \"Value\": \"true\"\n",
    "                                                    }\n",
    "                                                }\n",
    "                                            }\n",
    "                                        }\n",
    "                                    }\n",
    "                                ]\n",
    "                            }\n",
    "                            }\n",
    "                        }''',\n",
    "                 'filters': '[]', \n",
    "                 'height': 201.5, \n",
    "                 'width': 265.43, \n",
    "                 'x': 270.03, \n",
    "                 'y': 30.12, \n",
    "                 'z': 1000.0\n",
    "            }\n",
    "        ]\n",
    "    }]\n",
    "\n",
    "labs.report.create_report_from_reportjson(report=report_name , dataset=\"AdventureWorks_model\" , report_json = pbi_report)\n",
    "report_id = resolve_report_id(report_name)\n",
    "\n",
    "from powerbiclient import Report\n",
    "report = Report(group_id=None, report_id=report_id)\n",
    "report.set_size(400,700)\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e9261c-598d-4591-9a0f-55734693cd0f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Show Lakehouse Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654b9316-66e3-49dc-ad07-ac29546f76eb",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "labs.lakehouse.get_lakehouse_tables(LakehouseName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show relationships for AdvenetureWorks_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720a9a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sempy.fabric as fabric\n",
    "from sempy.relationships import plot_relationship_metadata , find_relationships\n",
    "\n",
    "relationships = fabric.list_relationships(SemanticModelName)\n",
    "plot_relationship_metadata(relationships)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc59957-8148-44f9-8740-a9486f575ed8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Show history details for **DimDate**\n",
    "Look at small table first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbda0ed-b407-4321-a251-666b2ff32be2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "display(delta_analyzer_history(lakehouse=LakehouseName, table_name=\"DimDate\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e120ef6-33e7-4d60-8881-2e4fb7a2fe67",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Show history details for **FactInernetSales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff06d8f-5779-44a3-8e91-ea249768ba0a",
   "metadata": {
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "display(delta_analyzer_history(lakehouse=LakehouseName, table_name=\"FactInternetSales\"))\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b408195-a4e9-4cad-87e8-22abd7ddbc53",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Insert data to **FactInternetSales** using Append\n",
    "load an existing day of data to a dataframe\n",
    "update the OrderDateKey for all rows in the dataframe to 20221204\n",
    "Append the rows in the dataframe back to the FactInternetSales Delta Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2b66b2-187c-4bc5-802c-17898f171789",
   "metadata": {
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Get one day of data from existing table\n",
    "from pyspark.sql.functions import lit, min, max ,count\n",
    "df1 = spark.read.load(f\"abfss://{workspaceId}@onelake.dfs.fabric.microsoft.com/{lakehouseId}/Tables/FactInternetSales\")\n",
    "\n",
    "# Show Min, MAX and Count of rows\n",
    "# df1.agg(\n",
    "#     min(\"OrderDateKey\").alias(\"min_OrderDateKey\") ,\n",
    "#     max(\"OrderDateKey\").alias(\"max_OrderDateKey\") ,\n",
    "#     count(\"*\").alias(\"count_rows\")\n",
    "#     ).show()\n",
    "\n",
    "\n",
    "# Create a filtered dataframe to update and then append back onto the original table\n",
    "df2 = df1.filter(\"OrderDateKey='20221204'\")\n",
    "df2 = df2.withColumn(\"OrderDateKey\",lit(20050630))\n",
    "\n",
    "\n",
    "df2.write.mode(\"append\").save(f\"abfss://{workspaceId}@onelake.dfs.fabric.microsoft.com/{lakehouseId}/Tables/FactInternetSales\")\n",
    "time.sleep(4)\n",
    "display(delta_analyzer_history(lakehouse=LakehouseName, table_name=\"FactInternetSales\"))\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14762a35-868a-477b-8852-1e9059e9a97c",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "df1 = spark.read.load(f\"abfss://{workspaceId}@onelake.dfs.fabric.microsoft.com/{lakehouseId}/Tables/FactInternetSales\")\n",
    "\n",
    "# Show Min, MAX and Count of rows\n",
    "df1.agg(\n",
    "        min(\"OrderDateKey\").alias(\"min_OrderDateKey\") ,\n",
    "        max(\"OrderDateKey\").alias(\"max_OrderDateKey\") ,\n",
    "        count(\"*\").alias(\"count_rows\")\n",
    "        ).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b0be9b-2097-4a61-88b0-7f743387c957",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Load **FactInternetSales** into variable\n",
    "To perform some updates and deletes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8169b7c3-c667-430b-b338-4baee2b63f50",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "deltaTable = DeltaTable.forPath(spark, f\"abfss://{workspaceId}@onelake.dfs.fabric.microsoft.com/{lakehouseId}/Tables/FactInternetSales\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9ae181-a1e1-4001-b419-2c0302688656",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## **Delete** some rows from **FactInternetSales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d351f70c-d311-43a9-afec-f7b2afd182d4",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "deltaTable.delete(\"OrderDateKey = '20050701'\")\n",
    "time.sleep(4)\n",
    "display(delta_analyzer_history(lakehouse=LakehouseName, table_name=\"FactInternetSales\"))\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8d5f35-78d2-4d58-93b2-d123a11c5b06",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## **Update** some rows in **FactInternetSales**\n",
    "Set all values for OrderDateKey = 20220218 to be DiscountAmount of 1 (was 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba63b48-38b6-4fbc-94f8-a5141ef6e9eb",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "deltaTable.update(\n",
    "    condition= col(\"OrderDateKey\")=='20220218',\n",
    "    set = { \"DiscountAmount\":\"1\"}\n",
    ")\n",
    "time.sleep(4)\n",
    "display(delta_analyzer_history(lakehouse=LakehouseName, table_name=\"FactInternetSales\"))\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebcc5a8",
   "metadata": {},
   "source": [
    "## Turn OFF auto framing\n",
    "Must be done manually on the **AdventureWorks_model**\n",
    "\n",
    "Make sure you click apply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71df4b3",
   "metadata": {},
   "source": [
    "## Insert _more_ data to **FactInternetSales** using Append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1f2e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a filtered dataframe to update and then append back onto the original table\n",
    "df2 = df1.filter(\"OrderDateKey='20221204'\")\n",
    "df2 = df2.withColumn(\"OrderDateKey\",lit(20050629))\n",
    "\n",
    "\n",
    "df2.write.mode(\"append\").save(f\"abfss://{workspaceId}@onelake.dfs.fabric.microsoft.com/{lakehouseId}/Tables/FactInternetSales\")\n",
    "time.sleep(4)\n",
    "display(delta_analyzer_history(lakehouse=LakehouseName, table_name=\"FactInternetSales\"))\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db5cf9e",
   "metadata": {},
   "source": [
    "## **Update** some rows from **FactInternetSales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12a7bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable.update(\n",
    "    condition= col(\"OrderDateKey\")=='20220218',\n",
    "    set = { \"DiscountAmount\":\"2\"}\n",
    ")\n",
    "time.sleep(4)\n",
    "display(delta_analyzer_history(lakehouse=LakehouseName, table_name=\"FactInternetSales\"))\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5158d909",
   "metadata": {},
   "source": [
    "## **Delete** some rows from **FactInternetSales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8840a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable.delete(\"OrderDateKey = '20050702'\")\n",
    "time.sleep(4)\n",
    "display(delta_analyzer_history(lakehouse=LakehouseName, table_name=\"FactInternetSales\"))\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bf15d5",
   "metadata": {},
   "source": [
    "## Reframe model to update changes\n",
    "This code block attempts to reframe the Semantic model in a loop until successful, catching exceptions and retrying every 3 seconds.  Upon, success, it prints a confirmation message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8691e43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reframeOK:bool=False\n",
    "while not reframeOK:\n",
    "    try:\n",
    "        result:pandas.DataFrame = labs.refresh_semantic_model(dataset=SemanticModelName)\n",
    "        reframeOK=True\n",
    "    except:\n",
    "        print('Error with reframe... trying again.')\n",
    "        triggerMetadataRefresh()\n",
    "        sleep(3)\n",
    "\n",
    "print('Custom Semantic Model reframe OK')\n",
    "report"
   ]
  }
 ],
 "metadata": {
  "dependencies": {},
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  },
  "widgets": {}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
