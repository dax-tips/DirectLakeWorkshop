{"cells":[{"cell_type":"markdown","source":["# Lab 1: Create Direct Lake custom semantic model"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f09b6c60-d142-42f2-aa77-b714234d69d3"},{"cell_type":"markdown","source":["Create your a custom semantic model\n","- Add measures\n","- Add relationships\n","- Mark Date Table\n","- Set sortby columns\n","- Hide columns\n","- Run DAX Query and DMV"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8a880ae9-56d7-4aeb-99c1-5455f81bbb0a"},{"cell_type":"markdown","source":["## 1. Install Semantic Link Labs Python Library"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"dd099e87-89f6-45b2-b286-d7f8a12b6a04"},{"cell_type":"code","source":["%pip install -q semantic-link-labs"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f16ed5ca-a6ba-478a-b029-17b6db9b6308"},{"cell_type":"markdown","source":["## 2. Install Python Libraries"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"b0cc44ce-395c-4db3-8979-b06acf9f8ecf"},{"cell_type":"code","source":["import sempy_labs as labs\n","from sempy import fabric\n","import sempy\n","import pandas\n","import json\n","import time\n","\n","LakehouseName = \"AdventureWorks\"\n","SemanticModelName = f\"{LakehouseName}_model\""],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c9e841d6-a757-4029-aa71-88d4bd286c30"},{"cell_type":"markdown","source":["## 3. Create Lakehouse"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"5a99f94c-a564-4aca-b670-31da354b7b9c"},{"cell_type":"code","source":["lakehouses=labs.list_lakehouses()[\"Lakehouse Name\"]\n","if LakehouseName in lakehouses.values:\n","    lakehouseId = notebookutils.lakehouse.getWithProperties(LakehouseName)[\"id\"]\n","else:\n","    lakehouseId = fabric.create_lakehouse(LakehouseName)\n","\n","workspaceId = notebookutils.lakehouse.getWithProperties(LakehouseName)[\"workspaceId\"]\n","workspaceName = sempy.fabric.resolve_workspace_name(workspaceId)\n","print(f\"WorkspaceId = {workspaceId}, LakehouseID = {lakehouseId}, Workspace Name = {workspaceName}\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"760df625-543c-4289-b6cc-f043290d5879"},{"cell_type":"markdown","source":["### 2.1 Remove any unwanted semantic models"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"26e300a6-210a-4330-a0bb-816668f39544"},{"cell_type":"markdown","source":["This code will not get past line 1 unless changed to the following.\n","\n","```\n","if **True** :\n","```"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1f86958d-822a-4ad4-918c-ef246d83d100"},{"cell_type":"code","source":["if False:\n","    for index, row in sempy.fabric.list_items().iterrows():\n","        if row[\"Type\"] == \"SemanticModel\" and row[\"Display Name\"] != LakehouseName:\n","            sempy.fabric.delete_item(item_id=row[\"Id\"],workspace=workspaceId)\n","            print(f\"Deleted semantic model {row['Display Name']}\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"cdfc8d31-d34c-4094-a230-6f8f38950b22"},{"cell_type":"markdown","source":["## 4. Remove all tables from Adventureworks Lakehouse"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"10b5f6bd-a0a6-4fd8-af71-3a0fb0627801"},{"cell_type":"code","source":["if False:\n","    folders = notebookutils.fs.ls(f\"abfss://{workspaceId}@onelake.dfs.fabric.microsoft.com/{lakehouseId}/Tables\")\n","    for fileInfo in folders:\n","        print(f\"Deleting...{fileInfo.path}\")\n","        notebookutils.fs.rm(fileInfo.path,recurse=True)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ab220003-1229-42c0-bd8a-cedd967d3740"},{"cell_type":"markdown","source":["## 5. Copy data from source into local lakehouse"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"9ef6e83e-d5fd-4020-9766-c236ef176329"},{"cell_type":"code","source":["def loadDataToLakehouse(fromTable:str,toTable:str):\n","    workspaceId = notebookutils.lakehouse.getWithProperties(LakehouseName)[\"workspaceId\"]\n","    lakehouseId = notebookutils.lakehouse.getWithProperties(LakehouseName)[\"id\"]\n","    customer_df =spark.read.load(f\"abfss://81363cc3-0a91-4393-a10f-0d58415fddef@onelake.dfs.fabric.microsoft.com/69031e47-6b22-467d-80b6-9edab4f29f72/Tables/{fromTable}\")\n","    customer_df.write.mode(\"overwrite\").save(f\"abfss://{workspaceId}@onelake.dfs.fabric.microsoft.com/{lakehouseId}/Tables/{toTable}\")\n","    print(f\"Loaded {toTable}\")\n","\n","loadDataToLakehouse(\"adw_DimCustomer\"       ,\"DimCustomer\")\n","loadDataToLakehouse(\"adw_DimDate\"           ,\"DimDate\")\n","loadDataToLakehouse(\"adw_DimProduct\"        ,\"DimProduct\")\n","loadDataToLakehouse(\"adw_FactInternetSales\" ,\"FactInternetSales\")\n","print(\"Done\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"28505f17-8bf7-4400-a409-344c4d01b4ef"},{"cell_type":"markdown","source":["## 6. Trigger backround job to sync Lakehouse tables"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"0fff2996-0b1c-4792-99cd-8d61315e65da"},{"cell_type":"code","source":["##https://medium.com/@sqltidy/delays-in-the-automatically-generated-schema-in-the-sql-analytics-endpoint-of-the-lakehouse-b01c7633035d\n","\n","def triggerMetadataRefresh():\n","    client = fabric.FabricRestClient()\n","    response = client.get(f\"/v1/workspaces/{workspaceId}/lakehouses/{lakehouseId}\")\n","    sqlendpoint = response.json()['properties']['sqlEndpointProperties']['id']\n","\n","    # trigger sync\n","    uri = f\"/v1.0/myorg/lhdatamarts/{sqlendpoint}\"\n","    payload = {\"commands\":[{\"$type\":\"MetadataRefreshExternalCommand\"}]}\n","    response = client.post(uri,json= payload)\n","    batchId = response.json()['batchId']\n","\n","    # Monitor Progress\n","    statusuri = f\"/v1.0/myorg/lhdatamarts/{sqlendpoint}/batches/{batchId}\"\n","    statusresponsedata = client.get(statusuri).json()\n","    progressState = statusresponsedata['progressState']\n","    print(progressState)\n","    while progressState != \"success\":\n","        statusuri = f\"/v1.0/myorg/lhdatamarts/{sqlendpoint}/batches/{batchId}\"\n","        statusresponsedata = client.get(statusuri).json()\n","        progressState = statusresponsedata['progressState']\n","        print(progressState)\n","        time.sleep(1)\n","\n","    print('done')\n","\n","triggerMetadataRefresh()"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2d54e1aa-a94e-4efd-b40e-f497f54589e8"},{"cell_type":"markdown","source":["## 7. Create Custom Semantic Model from Lakehouse"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"525e16b1-9893-46d3-ac7d-93a4d1453c5e"},{"cell_type":"code","source":["#1. Generate list of ALL table names from lakehouse to add to Semantic Model\n","lakehouseTables:list = labs.lakehouse.get_lakehouse_tables(lakehouse=LakehouseName)[\"Table Name\"]\n","\n","#2 Create the semantic model\n","if sempy.fabric.list_items().query(f\"`Display Name`=='{LakehouseName}_model' & Type=='SemanticModel'  \").shape[0] ==0:\n","    labs.directlake.generate_direct_lake_semantic_model(dataset=f\"{LakehouseName}_model\",lakehouse_tables=lakehouseTables,workspace=workspaceName,lakehouse=lakehouseId,refresh=False,overwrite=True)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1f1e9cc7-de53-4c81-8408-9fb18ef4383a"},{"cell_type":"markdown","source":["## 8. Add model relationships"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"b9df3373-52ca-4e45-83a6-40e1b20c184d"},{"cell_type":"code","source":["with labs.tom.connect_semantic_model(dataset=SemanticModelName, readonly=False) as tom:\n","    #1. Remove any existing relationships\n","    for r in tom.model.Relationships:\n","        tom.model.Relationships.Remove(r)\n","\n","    #2. Creates correct relationships\n","    tom.add_relationship(from_table=\"FactInternetSales\", from_column=\"OrderDateKey\" , to_table=\"DimDate\"    , to_column=\"DateKey\"       , from_cardinality=\"many\" , to_cardinality=\"one\")\n","    tom.add_relationship(from_table=\"FactInternetSales\", from_column=\"CustomerKey\"  , to_table=\"DimCustomer\", to_column=\"CustomerKey\"   , from_cardinality=\"many\" , to_cardinality=\"one\")\n","    tom.add_relationship(from_table=\"FactInternetSales\", from_column=\"ProductKey\"   , to_table=\"DimProduct\" , to_column=\"ProductKey\"    , from_cardinality=\"many\" , to_cardinality=\"one\")\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6616193a-57df-4139-91ef-c73830331555"},{"cell_type":"markdown","source":["## 9. Add model measures"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"19ba5536-018c-402b-aa0f-663ee5e8d07f"},{"cell_type":"code","source":["with labs.tom.connect_semantic_model(dataset=SemanticModelName, readonly=False) as tom:\n","    #1. Remove any existing measures\n","    for t in tom.model.Tables:\n","        for m in t.Measures:\n","            tom.remove_object(m)\n","            print(f\"[{m.Name}] measure removed\")\n","\n","    tom.add_measure(table_name=\"FactInternetSales\" ,measure_name=\"Sum of Sales\",expression=\"SUM(FactInternetSales[SalesAmount])\")\n","    "],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0666631c-4221-4638-b8ff-10fee8a4f7df"},{"cell_type":"markdown","source":["## 10. Mark DimDate as Date Table"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"299ff91f-0362-4c3e-bf2e-60c64867cec8"},{"cell_type":"code","source":["with labs.tom.connect_semantic_model(dataset=SemanticModelName, readonly=False) as tom:\n","    tom.mark_as_date_table(table_name=\"DimDate\",column_name=\"Date\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5e8f48bf-893b-4a8f-92a1-e5e80b968840"},{"cell_type":"markdown","source":["## 11. Set Sort by Cols"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"4cb148df-8490-47fc-8e9c-6b8cbcb5fb6a"},{"cell_type":"code","source":["import json\n","tom = labs.tom.TOMWrapper(dataset=SemanticModelName, workspace=workspaceName, readonly=False)\n","tom.set_sort_by_column(table_name=\"DimDate\",column_name=\"MonthName\"       ,sort_by_column=\"MonthNumberOfYear\")\n","tom.set_sort_by_column(table_name=\"DimDate\",column_name=\"DayOfWeek\"       ,sort_by_column=\"DayNumberOfWeek\")\n","tom.model.SaveChanges()\n","\n","i:int=0\n","for t in tom.model.Tables:\n","    if t.Name==\"DimDate\":\n","        bim = json.dumps(tom.get_bim()[\"model\"][\"tables\"][i],indent=4)\n","        print(bim)\n","    i=i+1"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"468514f8-1e73-4732-a22f-b0ce5f3c8eea"},{"cell_type":"markdown","source":["## 12. Hide Fact Table columns"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"d7a7babd-5053-4dc5-97e1-4398e67dba26"},{"cell_type":"code","source":["i:int=0\n","for t in tom.model.Tables:\n","    if t.Name in [\"FactInternetSales\"]:\n","        for c in t.Columns:\n","            c.IsHidden=True\n","\n","        bim = json.dumps(tom.get_bim()[\"model\"][\"tables\"][i],indent=4)\n","        print(bim)\n","    i=i+1"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fc2dbe0c-7d08-4c11-963f-07b44c20f401"},{"cell_type":"markdown","source":["## 13. Reframe model to update changes"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"67cc341d-8682-4a4d-8b00-300d8723bcfc"},{"cell_type":"code","source":["reframeOK:bool=False\n","while not reframeOK:\n","    try:\n","        result:pandas.DataFrame = labs.refresh_semantic_model(dataset=SemanticModelName)\n","        reframeOK=True\n","    except:\n","        print('Error with reframe... trying again.')\n","        triggerMetadataRefresh()\n","        sleep(3)\n","\n","print('Custom Semantic Model reframe OK')"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"22ed6756-a8b0-4250-9062-3266ae563054"},{"cell_type":"markdown","source":["## 14. Create function to run DAX query with a server timings trace"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"7b5f25b5-949d-4794-b565-f4d8fea1c089"},{"cell_type":"code","source":["import warnings\n","import time\n","from Microsoft.AnalysisServices.Tabular import TraceEventArgs\n","from typing import Dict, List, Optional, Callable\n","\n","def runDMV():\n","    df = sempy.fabric.evaluate_dax(\n","        dataset=SemanticModelName, \n","        dax_string=\"\"\"\n","        \n","        SELECT \n","            MEASURE_GROUP_NAME AS [TABLE],\n","            ATTRIBUTE_NAME AS [COLUMN],\n","            DATATYPE ,\n","            DICTIONARY_SIZE \t\t    AS SIZE ,\n","            DICTIONARY_ISPAGEABLE \t\tAS PAGEABLE ,\n","            DICTIONARY_ISRESIDENT\t\tAS RESIDENT ,\n","            DICTIONARY_TEMPERATURE\t\tAS TEMPERATURE,\n","            DICTIONARY_LAST_ACCESSED\tAS LASTACCESSED \n","        FROM $SYSTEM.DISCOVER_STORAGE_TABLE_COLUMNS \n","        ORDER BY \n","            [DICTIONARY_TEMPERATURE] DESC\n","        \n","        \"\"\")\n","    display(df)\n","\n","def filter_func(e):\n","    retVal:bool=True\n","    if e.EventSubclass.ToString() == \"VertiPaqScanInternal\":\n","        retVal=False      \n","    #     #if e.EventSubClass.ToString() == \"VertiPaqScanInternal\":\n","    #     retVal=False\n","    return retVal\n","\n","\n","# define events to trace and their corresponding columns\n","def runQueryWithTrace (expr:str,workspaceName:str,SemanticModelName:str,Result:Optional[bool]=True,Trace:Optional[bool]=True,DMV:Optional[bool]=True):\n","    event_schema = fabric.Trace.get_default_query_trace_schema()\n","    event_schema.update({\"ExecutionMetrics\":[\"EventClass\",\"TextData\"]})\n","    del event_schema['VertiPaqSEQueryBegin']\n","    del event_schema['VertiPaqSEQueryCacheMatch']\n","    del event_schema['DirectQueryBegin']\n","\n","    warnings.filterwarnings(\"ignore\")\n","\n","    WorkspaceName = workspaceName\n","    SemanticModelName = SemanticModelName\n","\n","    with fabric.create_trace_connection(SemanticModelName,WorkspaceName) as trace_connection:\n","        # create trace on server with specified events\n","        with trace_connection.create_trace(\n","            event_schema=event_schema, \n","            name=\"Simple Query Trace\",\n","            filter_predicate=filter_func,\n","            stop_event=\"QueryEnd\"\n","            ) as trace:\n","\n","            trace.start()\n","\n","            df=sempy.fabric.evaluate_dax(\n","                dataset=SemanticModelName, \n","                dax_string=expr)\n","\n","            if Result:\n","                displayHTML(f\"<H2>####### DAX QUERY RESULT #######</H2>\")\n","                display(df)\n","\n","            # Wait 5 seconds for trace data to arrive\n","            time.sleep(5)\n","\n","            # stop Trace and collect logs\n","            final_trace_logs = trace.stop()\n","\n","    if Trace:\n","        displayHTML(f\"<H2>####### SERVER TIMINGS #######</H2>\")\n","        display(final_trace_logs)\n","    \n","    if DMV:\n","        displayHTML(f\"<H2>####### SHOW DMV RESULTS #######</H2>\")\n","        runDMV()\n","\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"8dab34d2-784f-4a4a-bf61-afdabb4c2b69"},{"cell_type":"markdown","source":["## 15. DAX Queries"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"7066ff6f-7914-447d-8c02-52840649358c"},{"cell_type":"code","source":["df=sempy.fabric.evaluate_dax(\n","    dataset=SemanticModelName, \n","    dax_string=\"\"\"\n","    \n","    evaluate tabletraits()\n","    \n","    \"\"\")\n","display(df)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"dcf138f4-df36-41c4-bb58-a6af71edd179"},{"cell_type":"code","source":["df=labs.directlake.get_direct_lake_guardrails()\n","display(df)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"b3394566-f8a8-4ee3-885b-766db5e8a615"},{"cell_type":"markdown","source":["## 16. Run DMV to check column details"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"3dae67a8-b41c-4c18-8898-aaf4e478e599"},{"cell_type":"code","source":["runDMV()"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"223acea6-6ac3-4f3a-b04d-603309daf706"},{"cell_type":"markdown","source":["## 17. Run DAX Query on custom semantic model"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"5bc2dcd3-fe61-4466-b7dd-f746bac1e05a"},{"cell_type":"code","source":["labs.clear_cache(SemanticModelName)\n","\n","df=sempy.fabric.evaluate_dax(\n","    dataset=SemanticModelName, \n","    dax_string=\"\"\"\n","    \n","    EVALUATE\n","        SUMMARIZECOLUMNS(\n","               \n","                DimDate[MonthName] ,\n","                \"Count of Transactions\" , COUNTROWS(FactInternetSales) ,\n","                \"Sum of Sales\" , [Sum of Sales] \n","        )\n","        ORDER BY [MonthName]\n","    \"\"\")\n","display(df)\n","\n","runDMV()"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"32cbd807-3013-40a4-b584-fda3428ab4be"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"environment":{}}},"nbformat":4,"nbformat_minor":5}