{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3061fb6e-1484-4072-af99-c85b1dd9ae60",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Lab 4: Direct Lake Fallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f49793d-8e6c-4850-bdd3-7ed9a85ea337",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "This lab assumes Lab 2 has been completed successfully and there is a Semantic Model named BigData_Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5e5ade-d660-4f81-ad51-3389bfdff8e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 1. Install Semantic Link Labs Python Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b8ffa9-7858-421b-b9c4-e0ea54e6e8f1",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "%pip install -q --disable-pip-version-check semantic-link-labs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2882579-4bac-4b21-99f6-f7b1bb020235",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 2. Setup Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3dc908-415a-4f5a-83c9-7d15693fb363",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "import sempy_labs as labs\n",
    "from sempy import fabric\n",
    "import sempy\n",
    "\n",
    "LakehouseName = \"BigData\"\n",
    "lakehouses = labs.list_lakehouses()[\"Lakehouse Name\"]\n",
    "for l in lakehouses:\n",
    "    if l.startswith(\"Big\"):\n",
    "        LakehouseName = l\n",
    "\n",
    "SemanticModelName = f\"{LakehouseName}_model\"\n",
    "\n",
    "lakehouses=labs.list_lakehouses()[\"Lakehouse Name\"]\n",
    "if LakehouseName in lakehouses.values:\n",
    "    lakehouseId = notebookutils.lakehouse.getWithProperties(LakehouseName)[\"id\"]\n",
    "else:\n",
    "    print(\"You need to complete Lab 2 to create the required lakehouse for this lab\")\n",
    "\n",
    "workspaceId = notebookutils.lakehouse.getWithProperties(LakehouseName)[\"workspaceId\"]\n",
    "workspaceName = sempy.fabric.resolve_workspace_name(workspaceId)\n",
    "print(f\"WorkspaceId = {workspaceId}, LakehouseID = {lakehouseId}, Workspace Name = {workspaceName}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2215d098-a518-442e-9f42-ff0bfac5c586",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 3. Create function to run DAX queries with a server timings trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39653352-568d-4144-88d4-9393f8e4a6b3",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "from Microsoft.AnalysisServices.Tabular import TraceEventArgs\n",
    "from typing import Dict, List, Optional, Callable\n",
    "import pandas\n",
    "\n",
    "def runDMV():\n",
    "    df = sempy.fabric.evaluate_dax(\n",
    "        dataset=SemanticModelName, \n",
    "        dax_string=\"\"\"\n",
    "        \n",
    "        SELECT \n",
    "            MEASURE_GROUP_NAME AS [TABLE],\n",
    "            ATTRIBUTE_NAME AS [COLUMN],\n",
    "            DATATYPE ,\n",
    "            DICTIONARY_SIZE \t\t    AS SIZE ,\n",
    "            DICTIONARY_ISPAGEABLE \t\tAS PAGEABLE ,\n",
    "            DICTIONARY_ISRESIDENT\t\tAS RESIDENT ,\n",
    "            DICTIONARY_TEMPERATURE\t\tAS TEMPERATURE,\n",
    "            DICTIONARY_LAST_ACCESSED\tAS LASTACCESSED \n",
    "        FROM $SYSTEM.DISCOVER_STORAGE_TABLE_COLUMNS \n",
    "        ORDER BY \n",
    "            [DICTIONARY_TEMPERATURE] DESC\n",
    "        \n",
    "        \"\"\")\n",
    "    display(df)\n",
    "\n",
    "def filter_func(e):\n",
    "    retVal:bool=True\n",
    "    if e.EventSubclass.ToString() == \"VertiPaqScanInternal\":\n",
    "        retVal=False      \n",
    "    #     #if e.EventSubClass.ToString() == \"VertiPaqScanInternal\":\n",
    "    #     retVal=False\n",
    "    return retVal\n",
    "\n",
    "# define events to trace and their corresponding columns\n",
    "def runQueryWithTrace (expr:str,workspaceName:str,SemanticModelName:str,Result:Optional[bool]=True,Trace:Optional[bool]=True,DMV:Optional[bool]=True,ClearCache:Optional[bool]=True) -> pandas.DataFrame :\n",
    "    event_schema = fabric.Trace.get_default_query_trace_schema()\n",
    "    event_schema.update({\"ExecutionMetrics\":[\"EventClass\",\"TextData\"]})\n",
    "    del event_schema['VertiPaqSEQueryBegin']\n",
    "    del event_schema['VertiPaqSEQueryCacheMatch']\n",
    "    del event_schema['DirectQueryBegin']\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    WorkspaceName = workspaceName\n",
    "    SemanticModelName = SemanticModelName\n",
    "\n",
    "    if ClearCache:\n",
    "        labs.clear_cache(SemanticModelName)\n",
    "\n",
    "    with fabric.create_trace_connection(SemanticModelName,WorkspaceName) as trace_connection:\n",
    "        # create trace on server with specified events\n",
    "        with trace_connection.create_trace(\n",
    "            event_schema=event_schema, \n",
    "            name=\"Simple Query Trace\",\n",
    "            filter_predicate=filter_func,\n",
    "            stop_event=\"QueryEnd\"\n",
    "            ) as trace:\n",
    "\n",
    "            trace.start()\n",
    "\n",
    "            df=sempy.fabric.evaluate_dax(\n",
    "                dataset=SemanticModelName, \n",
    "                dax_string=expr)\n",
    "\n",
    "            if Result:\n",
    "                displayHTML(f\"<H2>####### DAX QUERY RESULT #######</H2>\")\n",
    "                display(df)\n",
    "\n",
    "            # Wait 5 seconds for trace data to arrive\n",
    "            time.sleep(5)\n",
    "\n",
    "            # stop Trace and collect logs\n",
    "            final_trace_logs = trace.stop()\n",
    "\n",
    "    if Trace:\n",
    "        displayHTML(f\"<H2>####### SERVER TIMINGS #######</H2>\")\n",
    "        display(final_trace_logs)\n",
    "    \n",
    "    if DMV:\n",
    "        displayHTML(f\"<H2>####### SHOW DMV RESULTS #######</H2>\")\n",
    "        runDMV()\n",
    "\n",
    "    return final_trace_logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4343642-bc69-4bcb-98f8-a5b3305cf1dd",
   "metadata": {
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "runDMV()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c5dad7-c8b4-4b96-8974-63ba5f5adfbd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 4. Run query that involves a Direct Query Fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd98a66e-a7e3-4300-b094-b69405ac01f3",
   "metadata": {
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "trace1 = runQueryWithTrace(\n",
    "    \"\"\"\n",
    "    EVALUATE\n",
    "        SUMMARIZECOLUMNS(\n",
    "                dim_Date[FirstDateofMonth] ,\n",
    "                \"Count of Transactions\" , COUNTROWS(fact_myevents_1bln) ,\n",
    "                \"Sum of Sales (1bln)\" , [Sum of Sales (1bln)] ,\n",
    "                \"Sum of Sales (2bln)\" , [Sum of Sales (2bln)]\n",
    "        )\n",
    "        ORDER BY [FirstDateofMonth]\n",
    "    \"\"\" , workspaceName , SemanticModelName\n",
    ")\n",
    "display(trace1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb53a945-6d3d-4fda-b69e-f6b8cd897b1d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 5. Change Custom Semantic Model to be **Direct Lake Only**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec808ab-a554-4d3c-a28d-56238929e7ad",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "tom = labs.tom.TOMWrapper(dataset=SemanticModelName, workspace=workspaceName, readonly=False)\n",
    "tom.set_direct_lake_behavior(\"DirectLakeOnly\") ##  Can be set to any of ['Automatic', 'DirectLakeOnly', 'DirectQueryOnly'].\n",
    "tom.model.SaveChanges()\n",
    "print(\"Model changed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f661bdb2-1903-4ef6-b766-30b73811d726",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 6. Run query that involves a Direct Query Fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc20540-3924-43b4-944e-c93e93c43452",
   "metadata": {
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "from sempy import fabric\n",
    "x = sempy.fabric._client._adomd_connection.FabricAdomdException\n",
    "try:\n",
    "    runQueryWithTrace(\n",
    "        \"\"\"\n",
    "        EVALUATE\n",
    "            SUMMARIZECOLUMNS(\n",
    "                    dim_Date[FirstDateofMonth] ,\n",
    "                    \"Count of Transactions\" , COUNTROWS(fact_myevents_1bln) ,\n",
    "                    \"Sum of Sales (1bln)\" , [Sum of Sales (1bln)] ,\n",
    "                    \"Sum of Sales (2bln)\" , [Sum of Sales (2bln)]\n",
    "            )\n",
    "            ORDER BY [FirstDateofMonth]\n",
    "        \"\"\" , workspaceName , SemanticModelName\n",
    "    )\n",
    "except sempy.fabric._client._adomd_connection.FabricAdomdException as f:\n",
    "    print(f)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a643db15-d7a7-4327-b561-e4fac6be6b1c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 7. Change Custom Semantic Model to be **Automatic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21878901-92d5-4942-93d6-8f4a32bb1f95",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "tom = labs.tom.TOMWrapper(dataset=SemanticModelName, workspace=workspaceName, readonly=False)\n",
    "tom.set_direct_lake_behavior(\"Automatic\") ##  ['Automatic', 'DirectLakeOnly', 'DirectQueryOnly'].\n",
    "tom.model.SaveChanges()\n",
    "print(\"Model changed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1439dd-d98e-4ec9-92c8-d553c94091b6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 8. Run query that involves a Direct Query Fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2e727b-ebbe-481d-91be-893593089cc0",
   "metadata": {
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "trace2 = runQueryWithTrace(\n",
    "    \"\"\"\n",
    "    EVALUATE\n",
    "        SUMMARIZECOLUMNS(\n",
    "                dim_Date[FirstDateofMonth] ,\n",
    "                \"Count of Transactions\" , COUNTROWS(fact_myevents_1bln) ,\n",
    "                \"Sum of Sales (1bln)\" , [Sum of Sales (1bln)] ,\n",
    "                \"Sum of Sales (2bln)\" , [Sum of Sales (2bln)]\n",
    "        )\n",
    "        ORDER BY [FirstDateofMonth]\n",
    "    \"\"\" , workspaceName , SemanticModelName, Trace=False, DMV=False\n",
    ")\n",
    "display(trace2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fca18ae",
   "metadata": {},
   "source": [
    "## 9. Stop the Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cb4280",
   "metadata": {},
   "outputs": [],
   "source": [
    "mssparkutils.session.stop()"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "environment": {}
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
