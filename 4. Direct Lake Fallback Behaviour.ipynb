{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3061fb6e-1484-4072-af99-c85b1dd9ae60",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Lab 4: Direct Lake Fallback Behavior and Troubleshooting\n",
    "\n",
    "## Lab Overview üõ°Ô∏è\n",
    "This lab explores **Direct Lake fallback mechanisms** - understanding when, why, and how Direct Lake automatically falls back to SQL Endpoint mode for system protection and query reliability.\n",
    "\n",
    "### What is Direct Lake Fallback?\n",
    "**Fallback behavior** is Direct Lake's intelligent protection system that ensures queries always complete successfully by automatically switching execution modes when necessary:\n",
    "\n",
    "- **üõ°Ô∏è System protection**: Prevents memory exhaustion and system crashes\n",
    "- **üìä Query reliability**: Ensures queries complete even when exceeding Direct Lake limits\n",
    "- **‚ö° Transparent operation**: End users receive results regardless of execution mode\n",
    "- **üéØ Performance optimization**: Balances performance with resource constraints\n",
    "\n",
    "### Learning Objectives\n",
    "By completing this lab, you will master:\n",
    "\n",
    "- ‚úÖ **Fallback triggers**: Understanding conditions that cause fallback to SQL Endpoint\n",
    "- ‚úÖ **Execution modes**: Exploring Automatic, DirectLakeOnly, and DirectQueryOnly behaviors\n",
    "- ‚úÖ **Performance comparison**: Analyzing execution time and resource usage differences\n",
    "- ‚úÖ **Troubleshooting techniques**: Identifying and resolving fallback scenarios\n",
    "- ‚úÖ **Production strategies**: Configuring appropriate fallback behavior for enterprise use\n",
    "\n",
    "### Fallback Scenarios We'll Explore\n",
    "\n",
    "#### Common Fallback Triggers:\n",
    "| Trigger | Cause | Workshop Example |\n",
    "|---------|-------|------------------|\n",
    "| **Memory exhaustion** | Column dictionaries exceed available memory | 2B row aggregations |\n",
    "| **High cardinality** | Unique values exceed Direct Lake limits | Large dimension tables |\n",
    "| **Query complexity** | Complex calculations require SQL processing | Advanced DAX operations |\n",
    "| **Resource contention** | Multiple concurrent users | Simulated load scenarios |\n",
    "\n",
    "### Lab Prerequisites\n",
    "- **Lab 2 completion**: BigData lakehouse with billion-row tables and semantic model\n",
    "- **Understanding of Direct Lake**: Basic concepts from Labs 1-3\n",
    "- **Performance monitoring**: Familiarity with tracing and DMV analysis\n",
    "\n",
    "### Fallback Behavior Modes\n",
    "\n",
    "#### Configuration Options:\n",
    "- **üîÑ Automatic**: Intelligent fallback when needed (default)\n",
    "- **üéØ DirectLakeOnly**: Force Direct Lake mode, fail if not possible\n",
    "- **üìä DirectQueryOnly**: Always use SQL Endpoint for all queries\n",
    "\n",
    "Ready to master Direct Lake's protection mechanisms? Let's explore fallback behavior! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f49793d-8e6c-4850-bdd3-7ed9a85ea337",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Prerequisites and Lab Dependencies\n",
    "\n",
    "This lab builds directly on **Lab 2's infrastructure** to demonstrate fallback behavior with real billion-row scenarios:\n",
    "\n",
    "#### Required Artifacts from Lab 2:\n",
    "- **BigData lakehouse**: With OneLake shortcuts to billion-row tables\n",
    "- **BigData_model semantic model**: Configured with relationships and measures\n",
    "- **Billion-row tables**: fact_myevents_1bln and fact_myevents_2bln for stress testing\n",
    "- **Performance monitoring setup**: Tracing and DMV capabilities established\n",
    "\n",
    "#### Why Lab 2 is Essential:\n",
    "- **Realistic scale**: Billion-row tables naturally trigger fallback scenarios\n",
    "- **Performance stress**: Large datasets push Direct Lake to its limits\n",
    "- **Comparative analysis**: Compare fallback vs. Direct Lake performance\n",
    "- **Production relevance**: Real-world scale scenarios for enterprise learning\n",
    "\n",
    "#### Fallback Learning Strategy:\n",
    "1. **Baseline establishment**: Document normal Direct Lake behavior\n",
    "2. **Fallback triggering**: Intentionally exceed limits to observe fallback\n",
    "3. **Mode configuration**: Explore different fallback behavior settings\n",
    "4. **Performance analysis**: Compare execution paths and timing\n",
    "5. **Troubleshooting**: Identify and resolve fallback causes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5e5ade-d660-4f81-ad51-3389bfdff8e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 1. Install Semantic Link Labs Python Library\n",
    "\n",
    "### Advanced Fallback Analysis Capabilities\n",
    "For fallback behavior analysis, **Semantic Link Labs** provides specialized functionality:\n",
    "\n",
    "- üîç **Execution path tracing**: Detailed visibility into Direct Lake vs. SQL Endpoint execution\n",
    "- üõ†Ô∏è **Fallback configuration**: Programmatic control over fallback behavior modes\n",
    "- üìä **Performance comparison**: Tools for analyzing execution time differences\n",
    "- üéØ **Troubleshooting support**: Advanced diagnostics for fallback scenarios\n",
    "- üß† **Memory monitoring**: Real-time tracking of memory usage and limits\n",
    "\n",
    "### Why Fallback Analysis Requires Enhanced Tools\n",
    "Understanding fallback behavior involves complex system interactions:\n",
    "- **Multi-mode execution**: Direct Lake, SQL Endpoint, and hybrid scenarios\n",
    "- **Resource monitoring**: Memory, CPU, and storage utilization tracking\n",
    "- **Error handling**: Graceful handling of resource limit scenarios\n",
    "- **Configuration management**: Dynamic behavior mode switching\n",
    "- **Performance correlation**: Linking fallback triggers to performance impacts\n",
    "\n",
    "The enhanced tooling provides visibility into these complex interactions for effective troubleshooting and optimization.\n",
    "\n",
    "**Expected outcome**: Advanced tooling ready for comprehensive fallback behavior analysis and performance comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b8ffa9-7858-421b-b9c4-e0ea54e6e8f1",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "%pip install -q --disable-pip-version-check semantic-link-labs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2882579-4bac-4b21-99f6-f7b1bb020235",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 2. Configure Environment for Fallback Behavior Testing\n",
    "\n",
    "### Fallback Testing Environment Setup\n",
    "This section establishes the environment for systematic fallback behavior analysis:\n",
    "\n",
    "#### Core Libraries for Fallback Analysis:\n",
    "- **`sempy_labs`**: Fallback configuration and monitoring tools\n",
    "- **`sempy.fabric`**: Core model management and refresh capabilities\n",
    "\n",
    "### Intelligent Lab Dependency Detection\n",
    "```python\n",
    "LakehouseName = \"BigData\"\n",
    "lakehouses = labs.list_lakehouses()[\"Lakehouse Name\"]\n",
    "for l in lakehouses:\n",
    "    if l.startswith(\"Big\"):\n",
    "        LakehouseName = l\n",
    "```\n",
    "\n",
    "#### Smart Environment Discovery:\n",
    "- **Lab 2 dependency**: Automatically finds BigData lakehouse from Lab 2\n",
    "- **Flexible naming**: Adapts to various \"Big\" prefixed lakehouse names\n",
    "- **Error prevention**: Validates environment before attempting fallback tests\n",
    "\n",
    "### Prerequisite Validation Strategy\n",
    "```python\n",
    "if LakehouseName in lakehouses.values:\n",
    "    lakehouseId = notebookutils.lakehouse.getWithProperties(LakehouseName)[\"id\"]\n",
    "else:\n",
    "    print(\"You need to complete Lab 2 to create the required lakehouse for this lab\")\n",
    "```\n",
    "\n",
    "#### Why Validation is Critical for Fallback Testing:\n",
    "- **Billion-row dependency**: Fallback scenarios require large datasets to trigger naturally\n",
    "- **Model configuration**: Semantic model must be properly configured with relationships\n",
    "- **Infrastructure readiness**: OneLake shortcuts and big data access must be functional\n",
    "- **Performance baseline**: Need established performance patterns for comparison\n",
    "\n",
    "### Environment Context for Fallback Analysis\n",
    "The environment setup provides:\n",
    "- **Target identification**: Clear identification of lakehouse and semantic model for testing\n",
    "- **Cross-workspace connectivity**: Maintained access to billion-row data sources\n",
    "- **Troubleshooting context**: Environment details for debugging fallback issues\n",
    "- **Performance baseline**: Established context for before/after comparisons\n",
    "\n",
    "**Expected outcome**: Validated environment with access to Lab 2's billion-row infrastructure, ready for systematic fallback behavior testing and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3dc908-415a-4f5a-83c9-7d15693fb363",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "import sempy_labs as labs\n",
    "from sempy import fabric\n",
    "import sempy\n",
    "\n",
    "LakehouseName = \"BigData\"\n",
    "lakehouses = labs.list_lakehouses()[\"Lakehouse Name\"]\n",
    "for l in lakehouses:\n",
    "    if l.startswith(\"Big\"):\n",
    "        LakehouseName = l\n",
    "\n",
    "SemanticModelName = f\"{LakehouseName}_model\"\n",
    "\n",
    "lakehouses=labs.list_lakehouses()[\"Lakehouse Name\"]\n",
    "if LakehouseName in lakehouses.values:\n",
    "    lakehouseId = notebookutils.lakehouse.getWithProperties(LakehouseName)[\"id\"]\n",
    "else:\n",
    "    print(\"You need to complete Lab 2 to create the required lakehouse for this lab\")\n",
    "\n",
    "workspaceId = notebookutils.lakehouse.getWithProperties(LakehouseName)[\"workspaceId\"]\n",
    "workspaceName = sempy.fabric.resolve_workspace_name(workspaceId)\n",
    "print(f\"WorkspaceId = {workspaceId}, LakehouseID = {lakehouseId}, Workspace Name = {workspaceName}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2215d098-a518-442e-9f42-ff0bfac5c586",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 3. Advanced Tracing for Fallback Behavior Analysis\n",
    "\n",
    "### Why Advanced Tracing is Essential for Fallback Analysis\n",
    "Understanding **fallback behavior** requires deep visibility into query execution paths and the decision-making process that triggers fallback:\n",
    "\n",
    "#### Critical Fallback Insights Needed:\n",
    "- **üîç Execution mode detection**: Identifying when queries use Direct Lake vs. SQL Endpoint\n",
    "- **‚è±Ô∏è Performance comparison**: Measuring execution time differences between modes\n",
    "- **üß† Resource utilization**: Understanding memory pressure and limits\n",
    "- **üõ°Ô∏è Fallback triggers**: Identifying exact conditions that cause fallback\n",
    "- **üìä Query path analysis**: Detailed breakdown of execution steps\n",
    "\n",
    "### Enhanced Tracing Architecture\n",
    "\n",
    "#### DMV Analysis Function:\n",
    "```python\n",
    "def runDMV():\n",
    "    # DISCOVER_STORAGE_TABLE_COLUMNS analysis\n",
    "```\n",
    "\n",
    "##### Key DMV Insights for Fallback:\n",
    "- **Column temperature**: Which columns are \"HOT\" vs. \"COLD\" affecting memory pressure\n",
    "- **Memory residency**: What's currently loaded vs. available memory\n",
    "- **Dictionary sizes**: Memory requirements that may trigger fallback\n",
    "- **Access patterns**: Usage patterns that influence fallback decisions\n",
    "\n",
    "#### Advanced Query Tracing Function:\n",
    "```python\n",
    "def runQueryWithTrace(expr, workspaceName, SemanticModelName, Result=True, Trace=True, DMV=True, ClearCache=True)\n",
    "```\n",
    "\n",
    "##### Fallback-Specific Tracing Features:\n",
    "\n",
    "###### **Execution Path Visibility**:\n",
    "- **DirectLake events**: Traces showing successful Direct Lake execution\n",
    "- **SQL Endpoint events**: Traces indicating fallback to SQL Analytics Endpoint\n",
    "- **Hybrid execution**: Mixed-mode execution patterns\n",
    "- **Error handling**: Graceful fallback transitions\n",
    "\n",
    "###### **Performance Correlation**:\n",
    "- **Timing analysis**: Execution time comparison between modes\n",
    "- **Resource monitoring**: Memory and CPU utilization during queries\n",
    "- **Bottleneck identification**: Performance limiting factors\n",
    "- **Optimization opportunities**: Areas for improvement\n",
    "\n",
    "### Event Filtering for Fallback Analysis\n",
    "```python\n",
    "def filter_func(e):\n",
    "    if e.EventSubclass.ToString() == \"VertiPaqScanInternal\":\n",
    "        return False  # Filter noise to focus on meaningful events\n",
    "    return True\n",
    "```\n",
    "\n",
    "#### Why Filtering Matters for Fallback:\n",
    "- **Signal vs. noise**: Focus on execution mode changes rather than internal operations\n",
    "- **Performance clarity**: Cleaner traces for fallback scenario analysis\n",
    "- **Resource efficiency**: Avoid overwhelming trace logs during billion-row operations\n",
    "\n",
    "### Comprehensive Analysis Framework\n",
    "\n",
    "#### Multi-Dimensional Analysis:\n",
    "- **Before/after comparison**: Clean memory state vs. post-query state\n",
    "- **Mode comparison**: Direct Lake vs. SQL Endpoint performance\n",
    "- **Resource impact**: Memory usage patterns and limits\n",
    "- **Fallback triggers**: Exact conditions causing mode switches\n",
    "\n",
    "#### Configurable Analysis Depth:\n",
    "- **Result display**: Optional query result visualization\n",
    "- **Trace analysis**: Detailed execution path breakdown\n",
    "- **DMV monitoring**: Memory and column state analysis\n",
    "- **Cache management**: Clean slate testing for consistent results\n",
    "\n",
    "**Expected outcome**: Comprehensive tracing framework ready to provide deep insights into fallback behavior, execution modes, and performance characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39653352-568d-4144-88d4-9393f8e4a6b3",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "from Microsoft.AnalysisServices.Tabular import TraceEventArgs\n",
    "from typing import Dict, List, Optional, Callable\n",
    "import pandas\n",
    "\n",
    "def runDMV():\n",
    "    df = sempy.fabric.evaluate_dax(\n",
    "        dataset=SemanticModelName, \n",
    "        dax_string=\"\"\"\n",
    "        \n",
    "        SELECT \n",
    "            MEASURE_GROUP_NAME AS [TABLE],\n",
    "            ATTRIBUTE_NAME AS [COLUMN],\n",
    "            DATATYPE ,\n",
    "            DICTIONARY_SIZE \t\t    AS SIZE ,\n",
    "            DICTIONARY_ISPAGEABLE \t\tAS PAGEABLE ,\n",
    "            DICTIONARY_ISRESIDENT\t\tAS RESIDENT ,\n",
    "            DICTIONARY_TEMPERATURE\t\tAS TEMPERATURE,\n",
    "            DICTIONARY_LAST_ACCESSED\tAS LASTACCESSED \n",
    "        FROM $SYSTEM.DISCOVER_STORAGE_TABLE_COLUMNS \n",
    "        ORDER BY \n",
    "            [DICTIONARY_TEMPERATURE] DESC\n",
    "        \n",
    "        \"\"\")\n",
    "    display(df)\n",
    "\n",
    "def filter_func(e):\n",
    "    retVal:bool=True\n",
    "    if e.EventSubclass.ToString() == \"VertiPaqScanInternal\":\n",
    "        retVal=False      \n",
    "    #     #if e.EventSubClass.ToString() == \"VertiPaqScanInternal\":\n",
    "    #     retVal=False\n",
    "    return retVal\n",
    "\n",
    "# define events to trace and their corresponding columns\n",
    "def runQueryWithTrace (expr:str,workspaceName:str,SemanticModelName:str,Result:Optional[bool]=True,Trace:Optional[bool]=True,DMV:Optional[bool]=True,ClearCache:Optional[bool]=True) -> pandas.DataFrame :\n",
    "    event_schema = fabric.Trace.get_default_query_trace_schema()\n",
    "    event_schema.update({\"ExecutionMetrics\":[\"EventClass\",\"TextData\"]})\n",
    "    del event_schema['VertiPaqSEQueryBegin']\n",
    "    del event_schema['VertiPaqSEQueryCacheMatch']\n",
    "    del event_schema['DirectQueryBegin']\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    WorkspaceName = workspaceName\n",
    "    SemanticModelName = SemanticModelName\n",
    "\n",
    "    if ClearCache:\n",
    "        labs.clear_cache(SemanticModelName)\n",
    "\n",
    "    with fabric.create_trace_connection(SemanticModelName,WorkspaceName) as trace_connection:\n",
    "        # create trace on server with specified events\n",
    "        with trace_connection.create_trace(\n",
    "            event_schema=event_schema, \n",
    "            name=\"Simple Query Trace\",\n",
    "            filter_predicate=filter_func,\n",
    "            stop_event=\"QueryEnd\"\n",
    "            ) as trace:\n",
    "\n",
    "            trace.start()\n",
    "\n",
    "            df=sempy.fabric.evaluate_dax(\n",
    "                dataset=SemanticModelName, \n",
    "                dax_string=expr)\n",
    "\n",
    "            if Result:\n",
    "                displayHTML(f\"<H2>####### DAX QUERY RESULT #######</H2>\")\n",
    "                display(df)\n",
    "\n",
    "            # Wait 5 seconds for trace data to arrive\n",
    "            time.sleep(5)\n",
    "\n",
    "            # stop Trace and collect logs\n",
    "            final_trace_logs = trace.stop()\n",
    "\n",
    "    if Trace:\n",
    "        displayHTML(f\"<H2>####### SERVER TIMINGS #######</H2>\")\n",
    "        display(final_trace_logs)\n",
    "    \n",
    "    if DMV:\n",
    "        displayHTML(f\"<H2>####### SHOW DMV RESULTS #######</H2>\")\n",
    "        runDMV()\n",
    "\n",
    "    return final_trace_logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4343642-bc69-4bcb-98f8-a5b3305cf1dd",
   "metadata": {
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "runDMV()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c5dad7-c8b4-4b96-8974-63ba5f5adfbd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 4. Demonstrate Natural Fallback Scenario (Automatic Mode)\n",
    "\n",
    "### Understanding Automatic Fallback Behavior\n",
    "This query demonstrates **natural fallback scenarios** using the default \"Automatic\" mode, where Direct Lake intelligently falls back to SQL Endpoint when necessary:\n",
    "\n",
    "#### Fallback-Triggering Query Design:\n",
    "```dax\n",
    "EVALUATE\n",
    "SUMMARIZECOLUMNS(\n",
    "    dim_Date[FirstDateofMonth],\n",
    "    \"Count of Transactions\", COUNTROWS(fact_myevents_1bln),\n",
    "    \"Sum of Sales (1bln)\", [Sum of Sales (1bln)],\n",
    "    \"Sum of Sales (2bln)\", [Sum of Sales (2bln)]\n",
    ")\n",
    "ORDER BY [FirstDateofMonth]\n",
    "```\n",
    "\n",
    "##### Why This Query May Trigger Fallback:\n",
    "- **üß† Memory pressure**: Loading both 1B and 2B row columns simultaneously\n",
    "- **üìä Resource competition**: Multiple large columns competing for memory\n",
    "- **‚ö° Complexity**: Cross-table aggregation with ordering requirements\n",
    "- **üîÑ Scale stress**: Testing system limits with maximum data volume\n",
    "\n",
    "### Expected Fallback Analysis\n",
    "\n",
    "#### Scenario 1: Direct Lake Success\n",
    "- **Sufficient memory**: Available memory can accommodate both large columns\n",
    "- **Execution traces**: Show DirectLake execution events\n",
    "- **Performance**: Reasonable execution time with memory loading\n",
    "- **DMV results**: Columns show \"HOT\" temperature and \"RESIDENT=TRUE\"\n",
    "\n",
    "#### Scenario 2: Automatic Fallback to SQL Endpoint\n",
    "- **Memory exhaustion**: Combined columns exceed available Direct Lake memory\n",
    "- **Execution traces**: Show fallback to SQL Analytics Endpoint\n",
    "- **Performance**: Different execution characteristics (possibly slower or faster)\n",
    "- **DMV results**: Columns may remain \"COLD\" due to SQL Endpoint execution\n",
    "\n",
    "### Fallback Benefits in Automatic Mode\n",
    "- **üõ°Ô∏è Query reliability**: Query completes successfully regardless of resource constraints\n",
    "- **üìä Consistent results**: Same analytical output regardless of execution mode\n",
    "- **‚ö° Performance optimization**: System chooses best execution path\n",
    "- **üë• User transparency**: End users unaware of execution mode changes\n",
    "\n",
    "**Expected outcome**: Baseline understanding of fallback behavior in natural scenarios, establishing foundation for comparing different fallback modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd98a66e-a7e3-4300-b094-b69405ac01f3",
   "metadata": {
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "trace1 = runQueryWithTrace(\n",
    "    \"\"\"\n",
    "    EVALUATE\n",
    "        SUMMARIZECOLUMNS(\n",
    "                dim_Date[FirstDateofMonth] ,\n",
    "                \"Count of Transactions\" , COUNTROWS(fact_myevents_1bln) ,\n",
    "                \"Sum of Sales (1bln)\" , [Sum of Sales (1bln)] ,\n",
    "                \"Sum of Sales (2bln)\" , [Sum of Sales (2bln)]\n",
    "        )\n",
    "        ORDER BY [FirstDateofMonth]\n",
    "    \"\"\" , workspaceName , SemanticModelName\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb53a945-6d3d-4fda-b69e-f6b8cd897b1d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 5. Configure DirectLakeOnly Mode for Strict Testing\n",
    "\n",
    "### Understanding DirectLakeOnly Behavior Mode\n",
    "**DirectLakeOnly** mode forces the semantic model to use only Direct Lake execution, **failing queries** rather than falling back to SQL Endpoint when limits are exceeded:\n",
    "\n",
    "#### DirectLakeOnly Characteristics:\n",
    "- **üéØ Strict enforcement**: No fallback allowed under any circumstances\n",
    "- **‚ùå Query failure**: Queries fail if Direct Lake limits are exceeded\n",
    "- **üîç Limit discovery**: Helps identify exact Direct Lake boundaries\n",
    "- **üõ†Ô∏è Troubleshooting**: Forces optimization to stay within Direct Lake constraints\n",
    "\n",
    "### Fallback Behavior Configuration\n",
    "```python\n",
    "tom.set_direct_lake_behavior(\"DirectLakeOnly\")\n",
    "```\n",
    "\n",
    "#### Available Behavior Modes:\n",
    "| Mode | Behavior | Use Case |\n",
    "|------|----------|----------|\n",
    "| **Automatic** | Intelligent fallback when needed | Production (default) |\n",
    "| **DirectLakeOnly** | Force Direct Lake, fail if impossible | Testing & optimization |\n",
    "| **DirectQueryOnly** | Always use SQL Endpoint | Troubleshooting scenarios |\n",
    "\n",
    "### Why Test DirectLakeOnly Mode?\n",
    "\n",
    "#### Performance Optimization Benefits:\n",
    "- **Boundary identification**: Discover exact memory and performance limits\n",
    "- **Optimization validation**: Confirm whether optimizations enable Direct Lake success\n",
    "- **Resource planning**: Understand infrastructure requirements for Direct Lake operation\n",
    "- **Query design guidance**: Identify query patterns that exceed Direct Lake capabilities\n",
    "\n",
    "#### Production Considerations:\n",
    "- **‚ö†Ô∏è Not recommended for production**: Query failures impact user experience\n",
    "- **üîß Development/testing use**: Ideal for optimization and troubleshooting phases\n",
    "- **üìä Performance analysis**: Valuable for understanding system limits\n",
    "- **üéØ Optimization goals**: Helps set targets for staying within Direct Lake bounds\n",
    "\n",
    "### Configuration Process\n",
    "```python\n",
    "tom.model.SaveChanges()                              # Apply configuration changes\n",
    "fabric.refresh_dataset(refresh_type=\"calculate\")     # Refresh to activate new behavior\n",
    "```\n",
    "\n",
    "#### Why Refresh is Required:\n",
    "- **Configuration activation**: New behavior mode must be applied to active model\n",
    "- **Memory reset**: Clear any cached execution plans or loaded columns\n",
    "- **Consistent testing**: Ensure clean state for DirectLakeOnly testing\n",
    "\n",
    "**Expected outcome**: Semantic model configured for strict Direct Lake-only execution, ready to test exact boundaries and failure scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec808ab-a554-4d3c-a28d-56238929e7ad",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "tom = labs.tom.TOMWrapper(dataset=SemanticModelName, workspace=workspaceName, readonly=False)\n",
    "tom.set_direct_lake_behavior(\"DirectLakeOnly\") ##  Can be set to any of ['Automatic', 'DirectLakeOnly', 'DirectQueryOnly'].\n",
    "tom.model.SaveChanges()\n",
    "print(\"Model changed\")\n",
    "fabric.refresh_dataset(refresh_type=\"calculate\",dataset=SemanticModelName)\n",
    "print(\"Model recalculated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f661bdb2-1903-4ef6-b766-30b73811d726",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 6. Test Query Failure in DirectLakeOnly Mode\n",
    "\n",
    "### Demonstrating DirectLakeOnly Failure Scenarios\n",
    "With the model configured for **DirectLakeOnly** mode, the same query that may have succeeded with automatic fallback will now **fail with a clear error** if Direct Lake limits are exceeded:\n",
    "\n",
    "#### Error Handling Strategy:\n",
    "```python\n",
    "try:\n",
    "    runQueryWithTrace(query, workspaceName, SemanticModelName)\n",
    "except sempy.fabric._client._adomd_connection.FabricAdomdException as f:\n",
    "    print(f)  # Display Fabric-specific error details\n",
    "except Exception as e:\n",
    "    print(e)  # Handle any other exceptions\n",
    "```\n",
    "\n",
    "### Expected DirectLakeOnly Behaviors\n",
    "\n",
    "#### Scenario 1: Direct Lake Success\n",
    "- **Within limits**: Query succeeds if memory and resource requirements are met\n",
    "- **Performance insight**: Pure Direct Lake performance without fallback possibility\n",
    "- **Resource validation**: Confirms the query can operate within Direct Lake constraints\n",
    "- **Optimization success**: Demonstrates successful optimization for Direct Lake operation\n",
    "\n",
    "#### Scenario 2: DirectLakeOnly Failure\n",
    "- **Resource exhaustion**: Query fails when exceeding Direct Lake memory limits\n",
    "- **Clear error messages**: Specific error indicating why Direct Lake failed\n",
    "- **Troubleshooting insight**: Exact understanding of limitation boundaries\n",
    "- **Optimization guidance**: Clear targets for performance optimization\n",
    "\n",
    "### Common DirectLakeOnly Error Messages\n",
    "\n",
    "#### Memory-Related Errors:\n",
    "- **\"Insufficient memory\"**: Column dictionaries exceed available Direct Lake memory\n",
    "- **\"Memory allocation failed\"**: System unable to allocate required memory for columns\n",
    "- **\"Column dictionary too large\"**: Individual columns exceed size limits\n",
    "\n",
    "#### Resource-Related Errors:\n",
    "- **\"Cardinality limits exceeded\"**: Unique values in columns exceed Direct Lake thresholds\n",
    "- **\"File size limits\"**: Individual parquet files exceed 1GB Direct Lake limit\n",
    "- **\"Concurrent user limits\"**: Too many users accessing large columns simultaneously\n",
    "\n",
    "### Learning Value of DirectLakeOnly Failures\n",
    "\n",
    "#### Optimization Insights:\n",
    "- **Specific bottlenecks**: Identify exact columns or operations causing failures\n",
    "- **Resource requirements**: Understand memory and infrastructure needs\n",
    "- **Query design impact**: See how query complexity affects Direct Lake viability\n",
    "- **Optimization priorities**: Focus optimization efforts on biggest impact areas\n",
    "\n",
    "#### Production Planning Benefits:\n",
    "- **Capacity planning**: Understand infrastructure requirements for Direct Lake success\n",
    "- **Fallback strategy**: Design appropriate fallback configurations for production\n",
    "- **User experience**: Balance performance optimization with query reliability\n",
    "- **Cost optimization**: Right-size infrastructure for Direct Lake requirements\n",
    "\n",
    "**Expected outcome**: Clear understanding of Direct Lake limits through controlled failure scenarios, providing specific guidance for optimization and production planning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc20540-3924-43b4-944e-c93e93c43452",
   "metadata": {
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "from sempy import fabric\n",
    "x = sempy.fabric._client._adomd_connection.FabricAdomdException\n",
    "try:\n",
    "    runQueryWithTrace(\n",
    "        \"\"\"\n",
    "        EVALUATE\n",
    "            SUMMARIZECOLUMNS(\n",
    "                    dim_Date[FirstDateofMonth] ,\n",
    "                    \"Count of Transactions\" , COUNTROWS(fact_myevents_1bln) ,\n",
    "                    \"Sum of Sales (1bln)\" , [Sum of Sales (1bln)] ,\n",
    "                    \"Sum of Sales (2bln)\" , [Sum of Sales (2bln)]\n",
    "            )\n",
    "            ORDER BY [FirstDateofMonth]\n",
    "        \"\"\" , workspaceName , SemanticModelName\n",
    "    )\n",
    "except sempy.fabric._client._adomd_connection.FabricAdomdException as f:\n",
    "    print(f)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a643db15-d7a7-4327-b561-e4fac6be6b1c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 7. Restore Automatic Mode for Production-Ready Behavior\n",
    "\n",
    "### Returning to Production-Ready Configuration\n",
    "After testing **DirectLakeOnly** mode for limit discovery, we restore **Automatic** mode for production-ready behavior that balances performance with reliability:\n",
    "\n",
    "#### Why Return to Automatic Mode:\n",
    "- **üõ°Ô∏è Query reliability**: Ensures all queries complete successfully\n",
    "- **‚ö° Performance optimization**: Leverages Direct Lake when possible, falls back when necessary\n",
    "- **üë• User experience**: Transparent operation without query failures\n",
    "- **üè≠ Production readiness**: Appropriate for end-user environments\n",
    "\n",
    "### Automatic Mode Benefits\n",
    "```python\n",
    "tom.set_direct_lake_behavior(\"Automatic\")  # Production-recommended setting\n",
    "```\n",
    "\n",
    "#### Intelligent Behavior Characteristics:\n",
    "- **Smart decision making**: System automatically chooses optimal execution mode\n",
    "- **Resource awareness**: Considers current memory availability and usage\n",
    "- **Performance optimization**: Prefers Direct Lake when resource constraints allow\n",
    "- **Graceful degradation**: Falls back to SQL Endpoint when necessary without user impact\n",
    "\n",
    "### Configuration Reset Process\n",
    "The model refresh ensures:\n",
    "- **Clean state**: Clear any previous DirectLakeOnly configuration artifacts\n",
    "- **Memory reset**: Fresh start for memory allocation and column loading\n",
    "- **Behavior activation**: New automatic behavior takes effect immediately\n",
    "- **Performance baseline**: Establish consistent baseline for comparative analysis\n",
    "\n",
    "**Expected outcome**: Model restored to production-ready automatic fallback behavior, ready for comparative performance analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21878901-92d5-4942-93d6-8f4a32bb1f95",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "tom = labs.tom.TOMWrapper(dataset=SemanticModelName, workspace=workspaceName, readonly=False)\n",
    "tom.set_direct_lake_behavior(\"Automatic\") ##  ['Automatic', 'DirectLakeOnly', 'DirectQueryOnly'].\n",
    "tom.model.SaveChanges()\n",
    "print(\"Model changed\")\n",
    "fabric.refresh_dataset(refresh_type=\"calculate\",dataset=SemanticModelName)\n",
    "print(\"Model recalculated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1439dd-d98e-4ec9-92c8-d553c94091b6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 8. Comparative Analysis: Automatic vs. DirectLakeOnly Performance\n",
    "\n",
    "### Final Fallback Behavior Comparison\n",
    "This concluding query provides **direct performance comparison** between the initial automatic mode execution and the current post-DirectLakeOnly test execution:\n",
    "\n",
    "#### Comparative Analysis Goals:\n",
    "- **Performance consistency**: Compare execution times between mode switches\n",
    "- **Behavior stability**: Ensure automatic mode functions correctly after DirectLakeOnly testing\n",
    "- **Resource impact**: Understand if previous failures affect subsequent performance\n",
    "- **Learning consolidation**: Synthesize insights from different fallback modes\n",
    "\n",
    "### Streamlined Analysis Configuration\n",
    "```python\n",
    "runQueryWithTrace(..., Trace=False, DMV=False)\n",
    "```\n",
    "\n",
    "#### Why Reduce Output for Final Test:\n",
    "- **Focus on results**: Emphasize query completion and timing over detailed traces\n",
    "- **Clean comparison**: Avoid information overload during comparative analysis\n",
    "- **Performance clarity**: Highlight execution time differences clearly\n",
    "- **Learning synthesis**: Consolidate key insights without excessive detail\n",
    "\n",
    "### Expected Comparative Insights\n",
    "\n",
    "#### Performance Comparison Matrix:\n",
    "| Execution | Mode | Expected Outcome | Learning Value |\n",
    "|-----------|------|------------------|----------------|\n",
    "| **First run** | Automatic | Direct Lake or graceful fallback | Baseline behavior |\n",
    "| **Second run** | DirectLakeOnly | Success or controlled failure | Limit understanding |\n",
    "| **Third run** | Automatic | Consistent with first run | Behavior stability |\n",
    "\n",
    "#### Key Performance Metrics:\n",
    "- **Execution time**: Consistency across automatic mode executions\n",
    "- **Resource usage**: Memory allocation patterns\n",
    "- **Result accuracy**: Identical analytical outputs regardless of execution mode\n",
    "- **System stability**: Reliable performance after mode switching\n",
    "\n",
    "### Fallback Behavior Mastery Summary\n",
    "\n",
    "#### Production Insights Gained:\n",
    "- ‚úÖ **Fallback triggers**: Understanding conditions that cause SQL Endpoint fallback\n",
    "- ‚úÖ **Performance impact**: Comparing Direct Lake vs. SQL Endpoint execution characteristics\n",
    "- ‚úÖ **Resource limits**: Exact boundaries of Direct Lake memory and performance constraints\n",
    "- ‚úÖ **Configuration strategies**: Appropriate fallback mode selection for different scenarios\n",
    "- ‚úÖ **Troubleshooting skills**: Identifying and resolving fallback-related issues\n",
    "\n",
    "**Expected outcome**: Comprehensive understanding of Direct Lake fallback behavior with practical insights for production deployment and optimization strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2e727b-ebbe-481d-91be-893593089cc0",
   "metadata": {
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "trace2 = runQueryWithTrace(\n",
    "    \"\"\"\n",
    "    EVALUATE\n",
    "        SUMMARIZECOLUMNS(\n",
    "                dim_Date[FirstDateofMonth] ,\n",
    "                \"Count of Transactions\" , COUNTROWS(fact_myevents_1bln) ,\n",
    "                \"Sum of Sales (1bln)\" , [Sum of Sales (1bln)] ,\n",
    "                \"Sum of Sales (2bln)\" , [Sum of Sales (2bln)]\n",
    "        )\n",
    "        ORDER BY [FirstDateofMonth]\n",
    "    \"\"\" , workspaceName , SemanticModelName, Trace=False, DMV=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fca18ae",
   "metadata": {},
   "source": [
    "## 9. Workshop Summary: Direct Lake Fallback Mastery\n",
    "\n",
    "### Comprehensive Learning Achievement Summary\n",
    "\n",
    "Congratulations! üéâ You have successfully completed the **Direct Lake Fallback Behaviour Workshop**, gaining essential skills for **production deployment** and **performance optimization** of Direct Lake solutions.\n",
    "\n",
    "### Core Competencies Developed\n",
    "\n",
    "#### üîç **1. Fallback Mechanism Understanding**\n",
    "- **Automatic mode benefits**: Intelligent fallback providing reliability and performance optimization\n",
    "- **DirectLakeOnly constraints**: Understanding exact limitations and appropriate use cases\n",
    "- **Trigger identification**: Recognizing conditions that cause SQL Endpoint fallback\n",
    "- **Performance implications**: Comparing execution characteristics across different modes\n",
    "\n",
    "#### ‚ö° **2. Performance Analysis Expertise**\n",
    "- **DMV interpretation**: Reading and understanding DirectQuery performance metrics\n",
    "- **Trace analysis**: Identifying performance bottlenecks and optimization opportunities\n",
    "- **Comparative benchmarking**: Evaluating relative performance across fallback modes\n",
    "- **Resource monitoring**: Understanding memory, CPU, and I/O impacts\n",
    "\n",
    "#### üéØ **3. Production Optimization Strategies**\n",
    "- **Configuration selection**: Choosing appropriate fallback modes for different scenarios\n",
    "- **Capacity planning**: Understanding resource requirements and limitations\n",
    "- **Troubleshooting workflows**: Systematic approaches to fallback-related issues\n",
    "- **Performance tuning**: Optimizing queries and models for Direct Lake efficiency\n",
    "\n",
    "### Practical Production Applications\n",
    "\n",
    "#### **Scenario-Based Decision Making:**\n",
    "\n",
    "| Business Scenario | Recommended Mode | Rationale |\n",
    "|-------------------|------------------|-----------|\n",
    "| **Real-time dashboards** | Automatic | Balance performance with reliability |\n",
    "| **Critical reporting** | Automatic | Ensure queries complete successfully |\n",
    "| **Performance testing** | DirectLakeOnly | Identify exact Direct Lake capabilities |\n",
    "| **Resource validation** | DirectLakeOnly | Test system boundaries and limits |\n",
    "\n",
    "#### **Troubleshooting Workflow Mastery:**\n",
    "1. **Identify**: Use DMVs to detect fallback occurrences\n",
    "2. **Analyze**: Examine traces to understand why fallback occurred\n",
    "3. **Optimize**: Modify queries or model to improve Direct Lake compatibility\n",
    "4. **Validate**: Test with DirectLakeOnly mode to confirm improvements\n",
    "5. **Deploy**: Use Automatic mode for production reliability\n",
    "\n",
    "### Advanced Insights Achieved\n",
    "\n",
    "#### **Performance Characteristics Understanding:**\n",
    "- ‚úÖ **Memory boundaries**: Exact limits where Direct Lake falls back to SQL Endpoint\n",
    "- ‚úÖ **Query complexity factors**: Identifying operations that trigger fallback\n",
    "- ‚úÖ **Data volume impacts**: Understanding how table size affects performance mode\n",
    "- ‚úÖ **Concurrency effects**: Recognizing how multiple users impact fallback behavior\n",
    "\n",
    "#### **Enterprise Deployment Readiness:**\n",
    "- ‚úÖ **Monitoring strategies**: Implementing fallback detection in production\n",
    "- ‚úÖ **Capacity planning**: Estimating resource requirements for optimal performance\n",
    "- ‚úÖ **User communication**: Explaining performance variations to business stakeholders\n",
    "- ‚úÖ **Optimization roadmaps**: Creating systematic improvement plans\n",
    "\n",
    "### Next Steps for Continued Learning\n",
    "\n",
    "#### **Immediate Applications:**\n",
    "1. **Apply learnings** to your production Direct Lake models\n",
    "2. **Implement monitoring** using the DMV queries learned today\n",
    "3. **Optimize existing queries** based on fallback behavior insights\n",
    "4. **Share knowledge** with your team about appropriate mode selection\n",
    "\n",
    "#### **Advanced Workshop Preparation:**\n",
    "- **Lab 5 - Framing**: Advanced refresh strategies and optimization techniques\n",
    "- **Lab 6 - Column Partitioning**: Performance optimization through strategic partitioning\n",
    "- **Lab 7 - High Cardinality Optimization**: Specialized techniques for complex data scenarios\n",
    "- **Lab 8 - Hybrid Scenarios**: Combining Direct Lake with Import mode effectively\n",
    "\n",
    "### Final Technical Validation\n",
    "\n",
    "Your completion of this workshop demonstrates:\n",
    "- üéØ **Expert-level understanding** of Direct Lake fallback mechanisms\n",
    "- üöÄ **Production-ready skills** for enterprise deployment\n",
    "- üîß **Advanced troubleshooting capabilities** for complex scenarios\n",
    "- üìä **Performance optimization expertise** for maximum efficiency\n",
    "\n",
    "**Congratulations on achieving Direct Lake Fallback Behaviour mastery!** You are now equipped with essential skills for successful enterprise deployment and optimization of Microsoft Fabric Direct Lake solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cb4280",
   "metadata": {},
   "outputs": [],
   "source": [
    "mssparkutils.session.stop()"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "environment": {}
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
