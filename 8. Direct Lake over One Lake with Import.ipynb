{"cells":[{"cell_type":"markdown","source":["# Lab 8: Direct Lake over One Lake with Import"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"15d63d4a-a0ee-4357-a020-7103ba035f01"},{"cell_type":"markdown","source":["## 1. Install Semantic Link Labs Python Library\n","This step installs Semantic Link Library which is a Python library design for use in Microsoft Fabric Notebooks.  The library extends the capabilities of [Semantic Link](https://learn.microsoft.com/en-us/fabric/data-science/semantic-link-overview) offering additional functionalities to seamlessly integrate alongside it."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"jupyter_python"},"jp-MarkdownHeadingCollapsed":true},"id":"4af395dd-b0d0-46a3-995f-d859eed2f903"},{"cell_type":"code","source":["%pip install -q --disable-pip-version-check semantic-link-labs"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"7e3356d3-7f40-4071-9a25-c42dfbdc27e1"},{"cell_type":"markdown","source":["## 2. Install Python Libraries\n","This step does the following:\n","- Sets up libraries that will be used iater in the script for various functions related to data processing, manipulation and handling\n","- Creates a populates the following variables\n","    - LakehouseName - Used as the name for the Lakehouse that will be created later in this script\n","    - SemanticModelName = Used as the  name for the Semantic Model that will be created later in this script"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"4e07e358-e8a6-4e44-8e9c-baf45bed2d18"},{"cell_type":"code","source":["import sempy_labs as labs\n","from sempy import fabric\n","import pandas as pd\n","import json\n","import time\n","import uuid\n","from sempy_labs.tom._model import TOMWrapper, connect_semantic_model\n","\n","from sempy_labs._helper_functions import (\n","    format_dax_object_name,\n","    generate_guid,\n","    _make_list_unique,\n","    resolve_dataset_name_and_id,\n","    resolve_workspace_name_and_id,\n","    _base_api,\n","    resolve_workspace_id,\n","    resolve_item_id,\n","    resolve_lakehouse_id,\n","    resolve_lakehouse_name_and_id\n",")\n","fabric._client._utils._init_analysis_services()\n","import Microsoft.AnalysisServices.Tabular as TOM\n","import Microsoft.AnalysisServices\n","\n","\n","LakehouseName = \"BigData\"\n","SemanticModelName = f\"{LakehouseName}_model\"\n","ClonedModelName = SemanticModelName + \"_clone\"\n","workspace = None\n","\n","\n","(workspace_name, workspace_id) = resolve_workspace_name_and_id(workspace)\n","(lakehouse_name, lakehouse_id) = resolve_lakehouse_name_and_id(lakehouse=LakehouseName, workspace=workspace)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"38dfd109-9068-486b-a42d-101366ce7554"},{"cell_type":"markdown","source":["## Clone BigData semantic model"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"4ca9aadf-8559-4d03-b64b-00f0fb6f02e8"},{"cell_type":"code","source":["#Clear any existing cloned model if re-running\n","df = fabric.list_items()\n","if ClonedModelName in df.values:\n","    model_id = df.at[df[df['Display Name'] == ClonedModelName].index[0], 'Id']\n","    fabric.delete_item(model_id)\n","    print(\"Cloned model deleted\")\n","\n","with labs.tom.connect_semantic_model(dataset=SemanticModelName, readonly=False) as tom:\n","    newDB = tom._tom_server.Databases.GetByName(SemanticModelName).Clone()\n","    newModel = tom._tom_server.Databases.GetByName(SemanticModelName).Model.Clone()\n","    newDB.Name = ClonedModelName\n","    newDB.ID = str(uuid.uuid4())\n","    #newDB.Model = newModel\n","    newModel.CopyTo(newDB.Model)\n","    tom._tom_server.Databases.Add(newDB)\n","\n","    newDB.Update(Microsoft.AnalysisServices.UpdateOptions.ExpandFull)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"59a99238-7a97-4adc-8e86-d83f6b03569d"},{"cell_type":"markdown","source":["## Frame the cloned model"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"jupyter_python"},"jp-MarkdownHeadingCollapsed":true},"id":"fc048908-0e39-4d19-8ab0-76e7b7119a23"},{"cell_type":"code","source":["labs.refresh_semantic_model(dataset=ClonedModelName)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"385bc2ca-99d8-4ab7-8905-690fd9d82f83"},{"cell_type":"markdown","source":["## Check what version of Direct Lake is being used\n","\n","##### Sql.Database    = DirectLake over SQL\n","\n","##### Azure.Lakehouse = DirectLake over One Lake"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"2748b06b-ddab-49ab-adbd-b11d5487881d"},{"cell_type":"code","source":["with labs.tom.connect_semantic_model(dataset=ClonedModelName, readonly=False) as tom:\n","    for e in tom.model.Expressions:\n","        print(e.Expression)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"6633e142-19e3-4595-b4c2-45e15d03f82a"},{"cell_type":"markdown","source":["## Show storage mode for each table in Cloned model"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"e7f4a9ee-1d8b-4f08-beac-68f66565b5d7"},{"cell_type":"code","source":["objects = {}\n","with labs.tom.connect_semantic_model(dataset=ClonedModelName, readonly=False) as tom:\n","    for t in tom.model.Tables:\n","        #print(t.Name)\n","        for p in t.Partitions:\n","            #print(p.Mode)\n","            objects[t.Name] = str(p.Mode)\n"," \n","df=pd.DataFrame([objects])\n","display(df)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"},"collapsed":false},"id":"ffea073c-45c6-4f3d-8a1f-059e6dd12501"},{"cell_type":"markdown","source":["## Try to convert Direct Lake table to Import\n","#### Will fail if Direct Lake over SQL"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"ec14e8e7-7a27-44b6-9bdb-7f6c5c7df19d"},{"cell_type":"code","source":["with labs.tom.connect_semantic_model(dataset=ClonedModelName, readonly=False) as tom:\n","    tom.convert_direct_lake_to_import(\n","        table_name=\"dim_Date\" ,\n","        entity_name=\"dim_Date\" ,\n","        source=\"BigData\",\n","        source_type = \"Lakehouse\"\n","    )"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"aeb7e6c2-6e56-40d9-b570-90976bc5eb60"},{"cell_type":"markdown","source":["## Convert cloned model to Direct Lake over One Lake"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"6021862b-6754-4ff9-827b-047a0dec4674"},{"cell_type":"code","source":["with labs.tom.connect_semantic_model(dataset=ClonedModelName, readonly=False) as tom:\n","\n","    #Convert import tables to Direct Lake\n","    for t in tom.model.Tables:\n","        for p in t.Partitions:\n","            if(p.Mode==TOM.ModeType.Import):\n","                t.Partitions.Remove(p)\n","                tom.add_entity_partition(table_name=t.Name,entity_name=t.Name)\n","                print(f\"Table {t.Name} converted\")\n","            p.Source.SchemaName=None\n","\n","    for e in tom.model.Expressions:\n","        e.Expression = f\"\"\"\n","        let\n","            Source = AzureStorage.DataLake(\"https://northcentralus-onelake.dfs.fabric.microsoft.com/{workspace_id}/{lakehouse_id}\", [HierarchicalNavigation=true])\n","        in\n","            Source\"\"\"\n","        \n","print(\"Converted Import tables back to Direct Lake (on One Lake)\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"e38ac75c-ae9c-4c06-8017-8341c71d50ae"},{"cell_type":"markdown","source":["## Try to convert Direct Lake table to Import (_attempt 2_)\n","#### Should work this time now model is Direct Lake over One Lake"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"a7d226b6-0dfc-422d-a656-bc35a2ed12c5"},{"cell_type":"code","source":["with labs.tom.connect_semantic_model(dataset=ClonedModelName, readonly=False) as tom:\n","    tom.convert_direct_lake_to_import(\n","        table_name=\"dim_Date\" ,\n","        entity_name=\"dim_Date\" ,\n","        source=\"BigData\",\n","        source_type = \"Lakehouse\"\n","    )"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"396054e2-5eb2-4a0e-bdea-54b9ad278c1e"},{"cell_type":"markdown","source":["## Show storage mode for each table"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"d2a9c1ba-ec93-48c4-a7c8-721ac6b98500"},{"cell_type":"code","source":["objects = {}\n","with labs.tom.connect_semantic_model(dataset=ClonedModelName, readonly=False) as tom:\n","    for t in tom.model.Tables:\n","        #print(t.Name)\n","        for p in t.Partitions:\n","            #print(p.Mode)\n","            objects[t.Name] = str(p.Mode)\n"," \n","df=pd.DataFrame([objects])\n","display(df)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"},"collapsed":false},"id":"6a9a8f7e-c0b2-4b01-ab63-67ab0cb8cc3a"},{"cell_type":"markdown","source":["## <mark>SET CREDENTIALS AND LARGE MODEL IN SERVICE</mark>"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"2868820b-7b38-4fb9-b438-a3aac82b24ae"},{"cell_type":"markdown","source":["## Refresh import table model so import table gets hydrated"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"d2d3da9d-c267-4dcf-8fbd-36f80c26505a"},{"cell_type":"code","source":["labs.refresh_semantic_model(dataset=ClonedModelName,tables=[\"dim_Date\"])"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"c447cca4-0e31-4492-af98-0ae0d96ace79"},{"cell_type":"markdown","source":["## Recalculate relationship indexes"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"jupyter_python"},"jp-MarkdownHeadingCollapsed":true},"id":"7cd6b65d-4119-457a-b1d4-98a1d935002b"},{"cell_type":"code","source":["labs.refresh_semantic_model(dataset=ClonedModelName,refresh_type=\"calculate\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"4649a743-9043-4a31-ba52-7ab1eeb9b4e7"},{"cell_type":"markdown","source":["## Show what version of Direct Lake is being used"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"bbbcef16-502c-4517-873b-90bafe383dbe"},{"cell_type":"code","source":["with labs.tom.connect_semantic_model(dataset=ClonedModelName, readonly=False) as tom:\n","    for e in tom.model.Expressions:\n","        print(e.Expression)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"33a5e7c6-6b05-4a7f-87a2-e05ed34df9ad"},{"cell_type":"markdown","source":["## Run query on 1Bln Row"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"jupyter_python"},"jp-MarkdownHeadingCollapsed":true},"id":"504bf7f1-ef01-40e9-b67f-0bc1efb82f07"},{"cell_type":"code","source":["df=fabric.evaluate_dax(\n","    dataset=ClonedModelName,\n","    dax_string=\"\"\"\n","        EVALUATE\n","\t        SUMMARIZECOLUMNS(\n","\t\t        dim_Date[DateKey],\n","\t\t        \"Quantity\" , [Sum of Sales (1bln)]\n","\t\t        )\n","        \"\"\"\n","    )\n","display(df)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"59b0ade2-ebf5-41d0-9c02-1016a8b1440a"},{"cell_type":"markdown","source":["## Run query on 2Bln Row\n","#### This will fail due to guardrail"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"jupyter_python"},"jp-MarkdownHeadingCollapsed":true},"id":"18476ac8-6970-4f8b-b41e-299c6e2752dd"},{"cell_type":"code","source":["df=fabric.evaluate_dax(\n","    dataset=ClonedModelName,\n","    dax_string=\"\"\"\n","        EVALUATE\n","\t        SUMMARIZECOLUMNS(\n","\t\t        dim_Date[DateKey],\n","\t\t        \"Quantity\" , [Sum of Sales (2bln)]\n","\t\t        )\n","        \"\"\"\n","\n","    )\n","display(df)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"2129efc8-5e63-4684-8b40-563ea586782e"},{"cell_type":"markdown","source":["## Convert cloned model to Direct Lake over SQL Endpoint"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"0e779019-d17c-43e3-b946-40b6f015bbcf"},{"cell_type":"code","source":["df=pd.DataFrame(labs.list_lakehouses())\n","endpointid = df[df['Lakehouse Name']==LakehouseName]['SQL Endpoint ID'].iloc[0]\n","server = df[df['Lakehouse Name']==LakehouseName]['SQL Endpoint Connection String'].iloc[0]\n","\n","with labs.tom.connect_semantic_model(dataset=ClonedModelName, readonly=False) as tom:\n","\n","    #Convert import tables to Direct Lake\n","    for t in tom.model.Tables:\n","        for p in t.Partitions:\n","            if(p.Mode==TOM.ModeType.Import):\n","                t.Partitions.Remove(p)\n","                tom.add_entity_partition(table_name=t.Name,entity_name=t.Name)\n","                print(f\"Table {t.Name} converted\")\n","            p.Source.SchemaName=None\n","\n","    #Switch Model to Direct Lake over SQL\n","    for e in tom.model.Expressions:\n","        e.Expression = f\"\"\"\n","        let\n","            Source = Sql.Database(\"{server}\", \"{endpointid}\")\n","        in\n","            Source\"\"\"\n","\n","        # if e.Name == \"DirectLake - AdventureWorks\" :\n","        #     tom.model.Expressions.Remove(e)\n","\n","print(\"Converted to Direct Lake over SQL\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"ff7d9159-f096-426c-ae42-9828e778887f"},{"cell_type":"code","source":["with labs.tom.connect_semantic_model(dataset=ClonedModelName, readonly=False) as tom:\n","    for e in tom.model.Expressions:\n","        print(e.Expression)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"848f1201-49d3-4e8a-af4d-b25460c836be"},{"cell_type":"markdown","source":["## Show storage mode for each table"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"4662bccf-96ff-4237-a167-739a9188ede7"},{"cell_type":"code","source":["objects = {}\n","with labs.tom.connect_semantic_model(dataset=ClonedModelName, readonly=False) as tom:\n","    for t in tom.model.Tables:\n","        #print(t.Name)\n","        for p in t.Partitions:\n","            #print(p.Mode)\n","            objects[t.Name] = str(p.Mode)\n"," \n","df=pd.DataFrame([objects])\n","display(df)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"},"collapsed":false},"id":"884eb022-3cfd-4faa-92e3-79f32525950d"},{"cell_type":"markdown","source":["## Run query on 2bln row table\n","This should work, but fall back to SQL Endpoint"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"jupyter_python"},"jp-MarkdownHeadingCollapsed":true},"id":"dc42ead8-fb11-4abc-be7b-bf99d2e170dd"},{"cell_type":"code","source":["df=fabric.evaluate_dax(\n","    dataset=ClonedModelName,\n","    dax_string=\"\"\"\n","        EVALUATE\n","\t        SUMMARIZECOLUMNS(\n","\t\t        dim_Date[DateKey],\n","\t\t        \"Quantity\" , [Sum of Sales (2bln)]\n","\t\t        )\n","        \"\"\"\n","    )\n","display(df)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"6546b0c5-fd4c-4ab8-8cf4-7a0f9064250d"},{"cell_type":"markdown","source":["## Show TMSL code for cloned model"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"124f1c63-8279-482b-b1d4-11bca298b658"},{"cell_type":"code","source":["import json\n","with labs.tom.connect_semantic_model(dataset=ClonedModelName, readonly=False) as tom:\n","    x= tom.get_bim()\n","\n","    formatted_json = json.dumps(x, indent=4)\n","    print(formatted_json)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"6d7266c6-802c-4819-9a84-42cb342d3df6"}],"metadata":{"kernel_info":{"name":"jupyter","jupyter_kernel_name":"python3.11"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"jupyter_python","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1800000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}